{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "195bc4b8",
      "metadata": {},
      "source": [
        "### Examining the facial emotion results\n",
        "\n",
        "I used the [vit-Facial-Expression-Recognition](https://huggingface.co/mo-thecreator/vit-Facial-Expression-Recognition) model to classify emotions on faces. This notebook analyzes the results and creates similar visualizations to the text sentiment analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "f6557974",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "from collections import defaultdict\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "3511fc5c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load facial emotions data\n",
        "df = pd.read_csv('results_facial_emotions.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "4f2c1b04",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 20603 entries, 0 to 20602\n",
            "Data columns (total 12 columns):\n",
            " #   Column                Non-Null Count  Dtype  \n",
            "---  ------                --------------  -----  \n",
            " 0   episode_key           20603 non-null  int64  \n",
            " 1   sketch_id             20603 non-null  int64  \n",
            " 2   frame_num_in_episode  20603 non-null  int64  \n",
            " 3   character_id          20603 non-null  int64  \n",
            " 4   bbox_x1               20603 non-null  float64\n",
            " 5   bbox_y1               20603 non-null  float64\n",
            " 6   bbox_x2               20603 non-null  float64\n",
            " 7   bbox_y2               20603 non-null  float64\n",
            " 8   det_score             20603 non-null  float64\n",
            " 9   emotion               20603 non-null  object \n",
            " 10  confidence            20603 non-null  float64\n",
            " 11  timestamp             20603 non-null  float64\n",
            "dtypes: float64(7), int64(4), object(1)\n",
            "memory usage: 1.9+ MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "dbf6d3bb",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total face detections: 20603\n",
            "Total sketches: 86\n",
            "Total episodes: 18\n",
            "Total seasons: 3\n",
            "\n",
            "Unique emotions: 7\n",
            "Unique categories: 22\n",
            "Unique characters: 65\n",
            "\n",
            "Emotion types: ['anger', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n"
          ]
        }
      ],
      "source": [
        "# Load metadata\n",
        "metadata = pd.read_csv('episode_metadata.csv')\n",
        "\n",
        "# Merge facial emotion data with metadata\n",
        "df_merged = df.merge(metadata, left_on='sketch_id', right_on='id', how='left')\n",
        "\n",
        "# Basic stats\n",
        "print(f\"Total face detections: {len(df)}\")\n",
        "print(f\"Total sketches: {df['sketch_id'].nunique()}\")\n",
        "print(f\"Total episodes: {df_merged.groupby(['season', 'episode']).ngroups if 'season' in df_merged.columns else 'N/A'}\")\n",
        "print(f\"Total seasons: {df_merged['season'].nunique() if 'season' in df_merged.columns else 'N/A'}\")\n",
        "print(f\"\\nUnique emotions: {df['emotion'].nunique()}\")\n",
        "print(f\"Unique categories: {df_merged['category'].nunique() if 'category' in df_merged.columns else 'N/A'}\")\n",
        "print(f\"Unique characters: {df['character_id'].nunique()}\")\n",
        "print(f\"\\nEmotion types: {sorted(df['emotion'].unique())}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "bf45f6c4",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    emotion  count  percentage\n",
            "0   neutral   5688   27.607630\n",
            "1       sad   4748   23.045188\n",
            "2     happy   4726   22.938407\n",
            "3  surprise   1750    8.493909\n",
            "4     anger   1559    7.566859\n",
            "5   disgust   1492    7.241664\n",
            "6      fear    640    3.106344\n",
            "Exported facial_overall_emotion_distribution.csv\n"
          ]
        }
      ],
      "source": [
        "# 1. Overall emotion distribution\n",
        "emotion_counts = df['emotion'].value_counts()\n",
        "emotion_counts\n",
        "# Calculate percentages\n",
        "emotion_counts_pct = emotion_counts / emotion_counts.sum() * 100\n",
        "\n",
        "# Combine into a DataFrame for export\n",
        "emotion_dist_df = pd.DataFrame({\n",
        "    'emotion': emotion_counts.index,\n",
        "    'count': emotion_counts.values,\n",
        "    'percentage': emotion_counts_pct.values\n",
        "})\n",
        "\n",
        "# Export to CSV\n",
        "emotion_dist_df.to_csv('facial_overall_emotion_distribution.csv', index=False)\n",
        "\n",
        "# Optionally, print for quick view\n",
        "print(emotion_dist_df)\n",
        "print(\"Exported facial_overall_emotion_distribution.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "660721ec",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top 5 emotions by category:\n",
            "    category   emotion  count  total  percentage\n",
            "4      class   neutral    135    442   30.542986\n",
            "5      class       sad    135    442   30.542986\n",
            "3      class     happy     70    442   15.837104\n",
            "2      class      fear     34    442    7.692308\n",
            "6      class  surprise     28    442    6.334842\n",
            "..       ...       ...    ...    ...         ...\n",
            "149     tour       sad    183    420   43.571429\n",
            "148     tour   neutral     99    420   23.571429\n",
            "147     tour     happy     90    420   21.428571\n",
            "144     tour     anger     24    420    5.714286\n",
            "146     tour      fear     13    420    3.095238\n",
            "\n",
            "[110 rows x 5 columns]\n"
          ]
        }
      ],
      "source": [
        "# 2. Emotions by category\n",
        "if 'category' in df_merged.columns:\n",
        "    category_emotion = df_merged.groupby(['category', 'emotion']).size().reset_index(name='count')\n",
        "    category_totals = df_merged.groupby('category').size()\n",
        "    \n",
        "    # Calculate percentages\n",
        "    category_emotion_pct = category_emotion.merge(\n",
        "        category_totals.reset_index(name='total'), \n",
        "        on='category'\n",
        "    )\n",
        "    category_emotion_pct['percentage'] = (category_emotion_pct['count'] / category_emotion_pct['total']) * 100\n",
        "    \n",
        "    # Top emotions per category\n",
        "    top_emotions_by_category = category_emotion_pct.sort_values(['category', 'count'], ascending=[True, False]).groupby('category').head(5)\n",
        "    print(\"Top 5 emotions by category:\")\n",
        "    print(top_emotions_by_category)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "40995083",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exported facial_top_emotions_by_category.csv\n"
          ]
        }
      ],
      "source": [
        "# Export top emotions by category\n",
        "if 'top_emotions_by_category' in locals():\n",
        "    top_emotions_by_category.to_csv('facial_top_emotions_by_category.csv', index=False)\n",
        "    print(f\"Exported facial_top_emotions_by_category.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "50a01b14",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Emotion distribution by season:\n",
            "    season   emotion  count  total  percentage\n",
            "4        1   neutral   2079   7024   29.598519\n",
            "3        1     happy   1689   7024   24.046128\n",
            "5        1       sad   1601   7024   22.793280\n",
            "6        1  surprise    603   7024    8.584852\n",
            "1        1   disgust    488   7024    6.947608\n",
            "12       2       sad   1676   6634   25.263793\n",
            "11       2   neutral   1669   6634   25.158276\n",
            "10       2     happy   1336   6634   20.138680\n",
            "13       2  surprise    665   6634   10.024118\n",
            "7        2     anger    542   6634    8.170033\n",
            "18       3   neutral   1940   6945   27.933765\n",
            "17       3     happy   1701   6945   24.492441\n",
            "19       3       sad   1471   6945   21.180706\n",
            "14       3     anger    623   6945    8.970482\n",
            "15       3   disgust    509   6945    7.329014\n"
          ]
        }
      ],
      "source": [
        "# 3. Emotions by season\n",
        "if 'season' in df_merged.columns:\n",
        "    season_emotion = df_merged.groupby(['season', 'emotion']).size().reset_index(name='count')\n",
        "    season_totals = df_merged.groupby('season').size()\n",
        "    \n",
        "    season_emotion_pct = season_emotion.merge(\n",
        "        season_totals.reset_index(name='total'),\n",
        "        on='season'\n",
        "    )\n",
        "    season_emotion_pct['percentage'] = (season_emotion_pct['count'] / season_emotion_pct['total']) * 100\n",
        "    \n",
        "    print(\"Emotion distribution by season:\")\n",
        "    print(season_emotion_pct.sort_values(['season', 'count'], ascending=[True, False]).groupby('season').head(5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "230ca0ef",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Emotions by position in sketch:\n",
            "   position_bin   emotion  count\n",
            "3     beginning     happy   1968\n",
            "4     beginning   neutral   1500\n",
            "5     beginning       sad   1056\n",
            "6     beginning  surprise    395\n",
            "1     beginning   disgust    307\n",
            "11       middle   neutral   2797\n",
            "12       middle       sad   2479\n",
            "10       middle     happy   1849\n",
            "13       middle  surprise    939\n",
            "7        middle     anger    864\n",
            "18          end   neutral   1391\n",
            "19          end       sad   1213\n",
            "17          end     happy    909\n",
            "20          end  surprise    416\n",
            "14          end     anger    414\n"
          ]
        }
      ],
      "source": [
        "# 4. Emotion evolution within sketches\n",
        "# Calculate relative position in sketch using timestamp\n",
        "# First, get sketch duration from metadata or calculate from data\n",
        "sketch_timestamps = df_merged.groupby('sketch_id')['timestamp'].agg(['min', 'max'])\n",
        "sketch_timestamps['duration'] = sketch_timestamps['max'] - sketch_timestamps['min']\n",
        "\n",
        "# Merge back to get relative position\n",
        "df_merged = df_merged.merge(sketch_timestamps[['duration']], left_on='sketch_id', right_index=True)\n",
        "df_merged['relative_position'] = (df_merged['timestamp'] - df_merged.groupby('sketch_id')['timestamp'].transform('min')) / df_merged['duration'].replace(0, 1)\n",
        "\n",
        "# Bin into beginning, middle, end\n",
        "df_merged['position_bin'] = pd.cut(df_merged['relative_position'], \n",
        "                            bins=[0, 0.25, 0.75, 1.0], \n",
        "                            labels=['beginning', 'middle', 'end'],\n",
        "                            include_lowest=True)\n",
        "\n",
        "position_emotion = df_merged.groupby(['position_bin', 'emotion'], observed=True).size().reset_index(name='count')\n",
        "print(\"Emotions by position in sketch:\")\n",
        "print(position_emotion.sort_values(['position_bin', 'count'], ascending=[True, False]).groupby('position_bin', observed=True).head(5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "aba48bdd",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Most emotional sketches (top 10):\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sketch_id</th>\n",
              "      <th>name</th>\n",
              "      <th>category</th>\n",
              "      <th>pct_neutral</th>\n",
              "      <th>avg_confidence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>53</td>\n",
              "      <td>Little Buff Boys Competition</td>\n",
              "      <td>commercial</td>\n",
              "      <td>0.040816</td>\n",
              "      <td>0.717186</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>42</td>\n",
              "      <td>Grambles Lorelei Lounge</td>\n",
              "      <td>restaurant</td>\n",
              "      <td>0.061674</td>\n",
              "      <td>0.699221</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>12</td>\n",
              "      <td>Which Hand</td>\n",
              "      <td>magic show</td>\n",
              "      <td>0.067073</td>\n",
              "      <td>0.679913</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>33</td>\n",
              "      <td>Corncob TV</td>\n",
              "      <td>commercial</td>\n",
              "      <td>0.069565</td>\n",
              "      <td>0.625446</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>57</td>\n",
              "      <td>Tammy Craps</td>\n",
              "      <td>commercial</td>\n",
              "      <td>0.087302</td>\n",
              "      <td>0.696341</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>52</td>\n",
              "      <td>Joanie's Birthday</td>\n",
              "      <td>party</td>\n",
              "      <td>0.100671</td>\n",
              "      <td>0.654336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Instagram</td>\n",
              "      <td>social media</td>\n",
              "      <td>0.107914</td>\n",
              "      <td>0.741256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>60</td>\n",
              "      <td>Barley Tonight</td>\n",
              "      <td>reality tv</td>\n",
              "      <td>0.113402</td>\n",
              "      <td>0.636396</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>39</td>\n",
              "      <td>Diner Wink</td>\n",
              "      <td>family</td>\n",
              "      <td>0.135417</td>\n",
              "      <td>0.624211</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>47</td>\n",
              "      <td>Wife Joke</td>\n",
              "      <td>party</td>\n",
              "      <td>0.136095</td>\n",
              "      <td>0.669517</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    sketch_id                          name      category  pct_neutral  \\\n",
              "52         53  Little Buff Boys Competition    commercial     0.040816   \n",
              "41         42       Grambles Lorelei Lounge    restaurant     0.061674   \n",
              "11         12                    Which Hand    magic show     0.067073   \n",
              "32         33                    Corncob TV    commercial     0.069565   \n",
              "56         57                   Tammy Craps    commercial     0.087302   \n",
              "51         52             Joanie's Birthday         party     0.100671   \n",
              "3           4                     Instagram  social media     0.107914   \n",
              "59         60                Barley Tonight    reality tv     0.113402   \n",
              "38         39                    Diner Wink        family     0.135417   \n",
              "46         47                     Wife Joke         party     0.136095   \n",
              "\n",
              "    avg_confidence  \n",
              "52        0.717186  \n",
              "41        0.699221  \n",
              "11        0.679913  \n",
              "32        0.625446  \n",
              "56        0.696341  \n",
              "51        0.654336  \n",
              "3         0.741256  \n",
              "59        0.636396  \n",
              "38        0.624211  \n",
              "46        0.669517  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Most neutral sketches (top 10):\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sketch_id</th>\n",
              "      <th>name</th>\n",
              "      <th>category</th>\n",
              "      <th>pct_neutral</th>\n",
              "      <th>avg_confidence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>78</td>\n",
              "      <td>Summer Loving Farewell Package</td>\n",
              "      <td>dating</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.798941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>15</td>\n",
              "      <td>New Joe</td>\n",
              "      <td>funeral</td>\n",
              "      <td>0.621795</td>\n",
              "      <td>0.676037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>40</td>\n",
              "      <td>The Shops at the Creeks</td>\n",
              "      <td>commercial</td>\n",
              "      <td>0.538462</td>\n",
              "      <td>0.778902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>85</td>\n",
              "      <td>Don Bondarley</td>\n",
              "      <td>party</td>\n",
              "      <td>0.489071</td>\n",
              "      <td>0.680591</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>18</td>\n",
              "      <td>A Christmas Carol</td>\n",
              "      <td>sci-fi/fantasy</td>\n",
              "      <td>0.471264</td>\n",
              "      <td>0.572971</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>22</td>\n",
              "      <td>Choking</td>\n",
              "      <td>restaurant</td>\n",
              "      <td>0.458042</td>\n",
              "      <td>0.668321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>35</td>\n",
              "      <td>Little Buff Boys</td>\n",
              "      <td>game show</td>\n",
              "      <td>0.455000</td>\n",
              "      <td>0.643889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>63</td>\n",
              "      <td>Dad Video</td>\n",
              "      <td>family</td>\n",
              "      <td>0.436709</td>\n",
              "      <td>0.676519</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>41</td>\n",
              "      <td>Baby Cries</td>\n",
              "      <td>party</td>\n",
              "      <td>0.426786</td>\n",
              "      <td>0.712872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>20</td>\n",
              "      <td>Traffic</td>\n",
              "      <td>driving</td>\n",
              "      <td>0.412541</td>\n",
              "      <td>0.688461</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    sketch_id                            name        category  pct_neutral  \\\n",
              "77         78  Summer Loving Farewell Package          dating     0.750000   \n",
              "14         15                         New Joe         funeral     0.621795   \n",
              "39         40         The Shops at the Creeks      commercial     0.538462   \n",
              "84         85                   Don Bondarley           party     0.489071   \n",
              "17         18               A Christmas Carol  sci-fi/fantasy     0.471264   \n",
              "21         22                         Choking      restaurant     0.458042   \n",
              "34         35                Little Buff Boys       game show     0.455000   \n",
              "62         63                       Dad Video          family     0.436709   \n",
              "40         41                      Baby Cries           party     0.426786   \n",
              "19         20                         Traffic         driving     0.412541   \n",
              "\n",
              "    avg_confidence  \n",
              "77        0.798941  \n",
              "14        0.676037  \n",
              "39        0.778902  \n",
              "84        0.680591  \n",
              "17        0.572971  \n",
              "21        0.668321  \n",
              "34        0.643889  \n",
              "62        0.676519  \n",
              "40        0.712872  \n",
              "19        0.688461  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 5. Most emotional vs. most neutral sketches\n",
        "sketch_stats = df_merged.groupby('sketch_id').agg({\n",
        "    'emotion': lambda x: (x == 'neutral').sum() / len(x) if len(x) > 0 else 0,  # % neutral\n",
        "    'confidence': ['mean', 'std'],\n",
        "    'timestamp': 'count'  # number of detections\n",
        "}).reset_index()\n",
        "sketch_stats.columns = ['sketch_id', 'pct_neutral', 'avg_confidence', 'confidence_std', 'num_detections']\n",
        "\n",
        "# Add sketch names and category\n",
        "sketch_stats = sketch_stats.merge(\n",
        "    df_merged[['sketch_id', 'name']].drop_duplicates(),\n",
        "    on='sketch_id'\n",
        ")\n",
        "if 'category' in df_merged.columns:\n",
        "    sketch_stats = sketch_stats.merge(\n",
        "        df_merged[['sketch_id', 'category']].drop_duplicates(),\n",
        "        on='sketch_id',\n",
        "        how='left'\n",
        "    )\n",
        "\n",
        "# Show 10 sketches with lowest % neutral (most emotional)\n",
        "most_emotional = sketch_stats.nsmallest(10, 'pct_neutral')[['sketch_id', 'name', 'category', 'pct_neutral', 'avg_confidence']]\n",
        "print(\"Most emotional sketches (top 10):\")\n",
        "display(most_emotional)\n",
        "\n",
        "# Show 10 sketches with highest % neutral (most neutral)\n",
        "most_neutral = sketch_stats.nlargest(10, 'pct_neutral')[['sketch_id', 'name', 'category', 'pct_neutral', 'avg_confidence']]\n",
        "print(\"\\nMost neutral sketches (top 10):\")\n",
        "display(most_neutral)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "a613ff1a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top emotions by character:\n",
            "     character_id  emotion  count  total  percentage\n",
            "4               0  neutral    953   3817   24.967252\n",
            "5               0      sad    900   3817   23.578727\n",
            "3               0    happy    824   3817   21.587634\n",
            "11              1  neutral    874   3253   26.867507\n",
            "12              1      sad    762   3253   23.424531\n",
            "..            ...      ...    ...    ...         ...\n",
            "283            86    happy      4      4  100.000000\n",
            "284            89    happy      1      1  100.000000\n",
            "286            92     fear      3      6   50.000000\n",
            "287            92      sad      2      6   33.333333\n",
            "285            92    anger      1      6   16.666667\n",
            "\n",
            "[163 rows x 5 columns]\n"
          ]
        }
      ],
      "source": [
        "# 6. Emotions by character\n",
        "character_emotion = df.groupby(['character_id', 'emotion']).size().reset_index(name='count')\n",
        "character_totals = df.groupby('character_id').size()\n",
        "\n",
        "character_emotion_pct = character_emotion.merge(\n",
        "    character_totals.reset_index(name='total'),\n",
        "    on='character_id'\n",
        ")\n",
        "character_emotion_pct['percentage'] = (character_emotion_pct['count'] / character_emotion_pct['total']) * 100\n",
        "\n",
        "print(\"Top emotions by character:\")\n",
        "print(character_emotion_pct.sort_values(['character_id', 'count'], ascending=[True, False]).groupby('character_id').head(3))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ddc34544",
      "metadata": {},
      "source": [
        "## Heatmap: Emotions Over Time for Each Sketch\n",
        "\n",
        "Prepare data for a heatmap showing emotion evolution across all sketches.\n",
        "- Y-axis: Sketches (ordered by season, episode, sketch_id)\n",
        "- X-axis: Time (normalized position within sketch, binned)\n",
        "- Color: Emotion type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "9868be72",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time bins: 20 bins (5.0% each)\n",
            "Total sketches: 86\n",
            "\n",
            "First few sketches in order:\n",
            "   sketch_id                            name  season  episode  sketch_order\n",
            "0          1                       Both Ways       1        1             0\n",
            "1          2  Has This Ever Happened to You?       1        1             1\n",
            "2          3                Baby of the Year       1        1             2\n",
            "3          4                       Instagram       1        1             3\n",
            "4          5                    Gift Receipt       1        1             4\n",
            "5          6                       Biker Guy       1        2             5\n",
            "6          7             River Mountain High       1        2             6\n",
            "7          8                Wilson's Toupees       1        2             7\n",
            "8          9                        Pink Bag       1        2             8\n",
            "9         10             River Mountain High       1        2             9\n"
          ]
        }
      ],
      "source": [
        "# Prepare data for sketch × time heatmap\n",
        "# Normalize time position for each sketch (0-100)\n",
        "df_merged['time_percent'] = df_merged['relative_position'] * 100\n",
        "\n",
        "# Create time bins (e.g., 0-5%, 5-10%, etc.)\n",
        "# Using 20 bins (5% increments) for good resolution without too much granularity\n",
        "NUM_TIME_BINS = 20\n",
        "df_merged['time_bin'] = pd.cut(df_merged['time_percent'], \n",
        "                        bins=NUM_TIME_BINS, \n",
        "                        labels=[f\"{i*100/NUM_TIME_BINS:.1f}-{(i+1)*100/NUM_TIME_BINS:.1f}%\" \n",
        "                                for i in range(NUM_TIME_BINS)],\n",
        "                        include_lowest=True)\n",
        "\n",
        "# Get sketch metadata for ordering\n",
        "if 'season' in df_merged.columns and 'episode' in df_merged.columns:\n",
        "    sketch_order = df_merged[['sketch_id', 'name', 'season', 'episode']].drop_duplicates().sort_values(\n",
        "        ['season', 'episode', 'sketch_id']\n",
        "    ).reset_index(drop=True)\n",
        "else:\n",
        "    sketch_order = df_merged[['sketch_id', 'name']].drop_duplicates().sort_values('sketch_id').reset_index(drop=True)\n",
        "    sketch_order['season'] = 0\n",
        "    sketch_order['episode'] = 0\n",
        "\n",
        "sketch_order['sketch_order'] = sketch_order.index\n",
        "\n",
        "# Add ordering to main dataframe\n",
        "df_merged = df_merged.merge(sketch_order[['sketch_id', 'sketch_order']], on='sketch_id')\n",
        "\n",
        "print(f\"Time bins: {NUM_TIME_BINS} bins ({100/NUM_TIME_BINS:.1f}% each)\")\n",
        "print(f\"Total sketches: {len(sketch_order)}\")\n",
        "print(f\"\\nFirst few sketches in order:\")\n",
        "print(sketch_order.head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "6e0a1f62",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample of ALL emotions by sketch × time bin:\n",
            "    sketch_id    time_bin   emotion  count  total_detections  percentage\n",
            "0           1    0.0-5.0%     anger      5                 9   55.555556\n",
            "1           1    0.0-5.0%     happy      2                 9   22.222222\n",
            "2           1    0.0-5.0%       sad      2                 9   22.222222\n",
            "3           1   5.0-10.0%     anger      5                13   38.461538\n",
            "4           1   5.0-10.0%     happy      5                13   38.461538\n",
            "5           1   5.0-10.0%   neutral      1                13    7.692308\n",
            "6           1   5.0-10.0%       sad      2                13   15.384615\n",
            "7           1  10.0-15.0%     anger      1                 6   16.666667\n",
            "8           1  10.0-15.0%     happy      3                 6   50.000000\n",
            "9           1  10.0-15.0%   neutral      1                 6   16.666667\n",
            "10          1  10.0-15.0%       sad      1                 6   16.666667\n",
            "11          1  15.0-20.0%   neutral      1                 5   20.000000\n",
            "12          1  15.0-20.0%       sad      3                 5   60.000000\n",
            "13          1  15.0-20.0%  surprise      1                 5   20.000000\n",
            "14          1  20.0-25.0%  surprise      1                 1  100.000000\n",
            "15          1  25.0-30.0%   disgust      2                 4   50.000000\n",
            "16          1  25.0-30.0%     happy      1                 4   25.000000\n",
            "17          1  25.0-30.0%   neutral      1                 4   25.000000\n",
            "18          1  30.0-35.0%   neutral      1                 3   33.333333\n",
            "19          1  30.0-35.0%       sad      2                 3   66.666667\n",
            "\n",
            "Total emotion × time_bin combinations: 6189\n",
            "Average emotions per sketch × time_bin: 3.72\n"
          ]
        }
      ],
      "source": [
        "# For each sketch × time_bin, capture ALL emotions (not just dominant)\n",
        "heatmap_data_all = df_merged.groupby(['sketch_id', 'time_bin', 'emotion'], observed=True).size().reset_index(name='count')\n",
        "\n",
        "# Calculate total detections per bin for percentages\n",
        "bin_totals = df_merged.groupby(['sketch_id', 'time_bin'], observed=True).size().reset_index(name='total_detections')\n",
        "heatmap_data_all = heatmap_data_all.merge(bin_totals, on=['sketch_id', 'time_bin'])\n",
        "heatmap_data_all['percentage'] = (heatmap_data_all['count'] / heatmap_data_all['total_detections']) * 100\n",
        "\n",
        "# Also determine the dominant emotion for comparison\n",
        "heatmap_data_sorted = heatmap_data_all.sort_values(['sketch_id', 'time_bin', 'count'], ascending=[True, True, False])\n",
        "dominant_emotions = heatmap_data_sorted.groupby(['sketch_id', 'time_bin'], observed=True).first().reset_index()\n",
        "dominant_emotions = dominant_emotions[['sketch_id', 'time_bin', 'emotion', 'count', 'total_detections']]\n",
        "dominant_emotions['dominance_ratio'] = dominant_emotions['count'] / dominant_emotions['total_detections']\n",
        "\n",
        "print(\"Sample of ALL emotions by sketch × time bin:\")\n",
        "print(heatmap_data_all.head(20))\n",
        "print(f\"\\nTotal emotion × time_bin combinations: {len(heatmap_data_all)}\")\n",
        "print(f\"Average emotions per sketch × time_bin: {heatmap_data_all.groupby(['sketch_id', 'time_bin'], observed=True).size().mean():.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "f3b976bd",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ALL emotions heatmap data shape: (6189, 15)\n",
            "Dominant-only heatmap data shape: (1662, 15)\n",
            "\n",
            "Sample of ALL emotions data:\n",
            "         name    time_bin   emotion  count  percentage\n",
            "0   Both Ways    0.0-5.0%     anger      5   55.555556\n",
            "1   Both Ways    0.0-5.0%     happy      2   22.222222\n",
            "2   Both Ways    0.0-5.0%       sad      2   22.222222\n",
            "3   Both Ways   5.0-10.0%     anger      5   38.461538\n",
            "4   Both Ways   5.0-10.0%     happy      5   38.461538\n",
            "5   Both Ways   5.0-10.0%       sad      2   15.384615\n",
            "6   Both Ways   5.0-10.0%   neutral      1    7.692308\n",
            "7   Both Ways  10.0-15.0%     happy      3   50.000000\n",
            "8   Both Ways  10.0-15.0%     anger      1   16.666667\n",
            "9   Both Ways  10.0-15.0%   neutral      1   16.666667\n",
            "10  Both Ways  10.0-15.0%       sad      1   16.666667\n",
            "11  Both Ways  15.0-20.0%       sad      3   60.000000\n",
            "12  Both Ways  15.0-20.0%   neutral      1   20.000000\n",
            "13  Both Ways  15.0-20.0%  surprise      1   20.000000\n",
            "14  Both Ways  20.0-25.0%  surprise      1  100.000000\n",
            "15  Both Ways  25.0-30.0%   disgust      2   50.000000\n",
            "16  Both Ways  25.0-30.0%     happy      1   25.000000\n",
            "17  Both Ways  25.0-30.0%   neutral      1   25.000000\n",
            "18  Both Ways  30.0-35.0%       sad      2   66.666667\n",
            "19  Both Ways  30.0-35.0%   neutral      1   33.333333\n"
          ]
        }
      ],
      "source": [
        "# Add sketch metadata and ordering to ALL emotions dataset\n",
        "heatmap_all_emotions = heatmap_data_all.merge(\n",
        "    sketch_order[['sketch_id', 'name', 'season', 'episode', 'sketch_order']],\n",
        "    on='sketch_id'\n",
        ")\n",
        "\n",
        "# Add category if available\n",
        "if 'category' in df_merged.columns:\n",
        "    sketch_categories = df_merged[['sketch_id', 'category', 'category2']].drop_duplicates()\n",
        "    heatmap_all_emotions = heatmap_all_emotions.merge(sketch_categories, on='sketch_id', how='left')\n",
        "\n",
        "# Convert time_bin to numeric for easier sorting/plotting\n",
        "heatmap_all_emotions['time_bin_start'] = heatmap_all_emotions['time_bin'].astype(str).str.split('-').str[0].str.rstrip('%').astype(float)\n",
        "heatmap_all_emotions['time_bin_end'] = heatmap_all_emotions['time_bin'].astype(str).str.split('-').str[1].str.rstrip('%').astype(float)\n",
        "heatmap_all_emotions['time_bin_center'] = (heatmap_all_emotions['time_bin_start'] + heatmap_all_emotions['time_bin_end']) / 2\n",
        "\n",
        "# Sort by sketch order, time bin, and count (descending)\n",
        "heatmap_all_emotions = heatmap_all_emotions.sort_values(['sketch_order', 'time_bin_start', 'count'], ascending=[True, True, False]).reset_index(drop=True)\n",
        "\n",
        "# Also create dominant-only version for comparison\n",
        "heatmap_export = dominant_emotions.merge(\n",
        "    sketch_order[['sketch_id', 'name', 'season', 'episode', 'sketch_order']],\n",
        "    on='sketch_id'\n",
        ")\n",
        "if 'category' in df_merged.columns:\n",
        "    heatmap_export = heatmap_export.merge(sketch_categories, on='sketch_id', how='left')\n",
        "heatmap_export['time_bin_start'] = heatmap_export['time_bin'].astype(str).str.split('-').str[0].str.rstrip('%').astype(float)\n",
        "heatmap_export['time_bin_end'] = heatmap_export['time_bin'].astype(str).str.split('-').str[1].str.rstrip('%').astype(float)\n",
        "heatmap_export['time_bin_center'] = (heatmap_export['time_bin_start'] + heatmap_export['time_bin_end']) / 2\n",
        "heatmap_export = heatmap_export.sort_values(['sketch_order', 'time_bin_start']).reset_index(drop=True)\n",
        "\n",
        "print(f\"ALL emotions heatmap data shape: {heatmap_all_emotions.shape}\")\n",
        "print(f\"Dominant-only heatmap data shape: {heatmap_export.shape}\")\n",
        "print(f\"\\nSample of ALL emotions data:\")\n",
        "print(heatmap_all_emotions[['name', 'time_bin', 'emotion', 'count', 'percentage']].head(20))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "bb284958",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Alternative version with confidence scores:\n",
            "         name    time_bin most_common_emotion  avg_confidence\n",
            "0   Both Ways    0.0-5.0%               anger        0.583908\n",
            "1   Both Ways   5.0-10.0%               anger        0.688675\n",
            "2   Both Ways  10.0-15.0%               happy        0.782999\n",
            "3   Both Ways  15.0-20.0%                 sad        0.497361\n",
            "4   Both Ways  20.0-25.0%            surprise        0.800216\n",
            "5   Both Ways  25.0-30.0%             disgust        0.578273\n",
            "6   Both Ways  30.0-35.0%                 sad        0.553286\n",
            "7   Both Ways  35.0-40.0%               happy        0.661433\n",
            "8   Both Ways  40.0-45.0%             disgust        0.575155\n",
            "9   Both Ways  50.0-55.0%             neutral        0.399828\n",
            "10  Both Ways  55.0-60.0%                fear        0.451276\n",
            "11  Both Ways  60.0-65.0%             neutral        0.655202\n",
            "12  Both Ways  65.0-70.0%               happy        0.877965\n",
            "13  Both Ways  70.0-75.0%               happy        0.839132\n",
            "14  Both Ways  75.0-80.0%               happy        0.883341\n"
          ]
        }
      ],
      "source": [
        "# Also create an alternative version with average confidence score per bin\n",
        "heatmap_score_data = df_merged.groupby(['sketch_id', 'time_bin'], observed=True).agg({\n",
        "    'confidence': 'mean',\n",
        "    'emotion': lambda x: x.mode()[0] if len(x.mode()) > 0 else 'neutral'  # most common emotion\n",
        "}).reset_index()\n",
        "heatmap_score_data.columns = ['sketch_id', 'time_bin', 'avg_confidence', 'most_common_emotion']\n",
        "\n",
        "# Add metadata\n",
        "heatmap_score_export = heatmap_score_data.merge(\n",
        "    sketch_order[['sketch_id', 'name', 'season', 'episode', 'sketch_order']],\n",
        "    on='sketch_id'\n",
        ")\n",
        "if 'category' in df_merged.columns:\n",
        "    heatmap_score_export = heatmap_score_export.merge(sketch_categories, on='sketch_id', how='left')\n",
        "\n",
        "# Add time bin numeric values\n",
        "heatmap_score_export['time_bin_start'] = heatmap_score_export['time_bin'].astype(str).str.split('-').str[0].str.rstrip('%').astype(float)\n",
        "heatmap_score_export['time_bin_end'] = heatmap_score_export['time_bin'].astype(str).str.split('-').str[1].str.rstrip('%').astype(float)\n",
        "heatmap_score_export['time_bin_center'] = (heatmap_score_export['time_bin_start'] + heatmap_score_export['time_bin_end']) / 2\n",
        "\n",
        "heatmap_score_export = heatmap_score_export.sort_values(['sketch_order', 'time_bin_start']).reset_index(drop=True)\n",
        "\n",
        "print(\"Alternative version with confidence scores:\")\n",
        "print(heatmap_score_export[['name', 'time_bin', 'most_common_emotion', 'avg_confidence']].head(15))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "ef4d177b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final heatmap datasets prepared:\n",
            "  - ALL emotions version: 6189 rows\n",
            "  - Dominant emotion version: 1662 rows\n",
            "  - Score-based version: 1662 rows\n",
            "\n",
            "Unique emotions across all sketches: 7\n",
            "Emotions: ['anger', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
            "\n",
            "Emotion diversity per sketch:\n",
            "  Average unique emotions per sketch: 6.77\n",
            "  Range: 3 - 7 unique emotions\n"
          ]
        }
      ],
      "source": [
        "# Create comprehensive exports with multiple versions\n",
        "# Version 1: ALL emotions per time bin\n",
        "heatmap_all_final = heatmap_all_emotions[[\n",
        "    'sketch_id', 'name', 'sketch_order', 'season', 'episode',\n",
        "    'time_bin', 'time_bin_start', 'time_bin_end', 'time_bin_center',\n",
        "    'emotion', 'count', 'total_detections', 'percentage'\n",
        "]].copy()\n",
        "\n",
        "if 'category' in heatmap_all_emotions.columns:\n",
        "    heatmap_all_final['category'] = heatmap_all_emotions['category']\n",
        "    if 'category2' in heatmap_all_emotions.columns:\n",
        "        heatmap_all_final['category2'] = heatmap_all_emotions['category2']\n",
        "\n",
        "# Version 2: Dominant emotion only\n",
        "heatmap_final = heatmap_export[[\n",
        "    'sketch_id', 'name', 'sketch_order', 'season', 'episode',\n",
        "    'time_bin', 'time_bin_start', 'time_bin_end', 'time_bin_center',\n",
        "    'emotion', 'count', 'total_detections', 'dominance_ratio'\n",
        "]].copy()\n",
        "\n",
        "if 'category' in heatmap_export.columns:\n",
        "    heatmap_final['category'] = heatmap_export['category']\n",
        "    if 'category2' in heatmap_export.columns:\n",
        "        heatmap_final['category2'] = heatmap_export['category2']\n",
        "\n",
        "# Version 3: Score-based version\n",
        "heatmap_score_final = heatmap_score_export[[\n",
        "    'sketch_id', 'name', 'sketch_order', 'season', 'episode',\n",
        "    'time_bin', 'time_bin_start', 'time_bin_end', 'time_bin_center',\n",
        "    'most_common_emotion', 'avg_confidence'\n",
        "]].copy()\n",
        "\n",
        "if 'category' in heatmap_score_export.columns:\n",
        "    heatmap_score_final['category'] = heatmap_score_export['category']\n",
        "    if 'category2' in heatmap_score_export.columns:\n",
        "        heatmap_score_final['category2'] = heatmap_score_export['category2']\n",
        "\n",
        "# Calculate emotion diversity metrics per sketch\n",
        "emotion_diversity = heatmap_all_emotions.groupby('sketch_id').agg({\n",
        "    'emotion': 'nunique',  # number of unique emotions\n",
        "    'count': 'sum'  # total detections\n",
        "}).reset_index()\n",
        "emotion_diversity.columns = ['sketch_id', 'num_unique_emotions', 'total_detections']\n",
        "emotion_diversity = emotion_diversity.merge(\n",
        "    sketch_order[['sketch_id', 'name', 'season', 'episode', 'sketch_order']],\n",
        "    on='sketch_id'\n",
        ")\n",
        "\n",
        "print(\"Final heatmap datasets prepared:\")\n",
        "print(f\"  - ALL emotions version: {len(heatmap_all_final)} rows\")\n",
        "print(f\"  - Dominant emotion version: {len(heatmap_final)} rows\")\n",
        "print(f\"  - Score-based version: {len(heatmap_score_final)} rows\")\n",
        "print(f\"\\nUnique emotions across all sketches: {heatmap_all_final['emotion'].nunique()}\")\n",
        "print(f\"Emotions: {sorted(heatmap_all_final['emotion'].unique())}\")\n",
        "print(f\"\\nEmotion diversity per sketch:\")\n",
        "print(f\"  Average unique emotions per sketch: {emotion_diversity['num_unique_emotions'].mean():.2f}\")\n",
        "print(f\"  Range: {emotion_diversity['num_unique_emotions'].min()} - {emotion_diversity['num_unique_emotions'].max()} unique emotions\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad9dd0f9",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "1e2c0586",
      "metadata": {},
      "source": [
        "## Data Structure: Emotions in Order of Appearance per Sketch\n",
        "\n",
        "Create a structured data format that organizes emotions chronologically for each sketch, making it easy to visualize the emotional arc over time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82d25ff8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total unique emotions: 7\n",
            "All emotions: ['anger', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
            "\n",
            "Columns in df_sorted: ['episode_key', 'sketch_id', 'frame_num_in_episode', 'character_id', 'bbox_x1', 'bbox_y1', 'bbox_x2', 'bbox_y2', 'det_score', 'emotion', 'confidence', 'timestamp', 'season', 'episode', 'id', 'name', 'start', 'end', 'category', 'category2', 'song', 'description', 'duration_x', 'relative_position', 'position_bin', 'duration_y', 'duration', 'time_percent', 'time_bin', 'sketch_order']\n"
          ]
        }
      ],
      "source": [
        "# Ensure data is sorted by sketch_id and timestamp for chronological order\n",
        "df_sorted = df_merged.sort_values(['sketch_id', 'timestamp', 'character_id']).reset_index(drop=True)\n",
        "\n",
        "# Get all unique emotions for reference\n",
        "all_emotions = sorted(df_sorted['emotion'].unique())\n",
        "print(f\"Total unique emotions: {len(all_emotions)}\")\n",
        "print(f\"All emotions: {all_emotions}\")\n",
        "print(f\"\\nColumns in df_sorted: {list(df_sorted.columns)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "a177d8e6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created data structure for 86 sketches\n",
            "\n",
            "Example structure for sketch 1:\n",
            "{\n",
            "  \"sketch_id\": 1,\n",
            "  \"sketch_name\": \"Both Ways\",\n",
            "  \"season\": 1,\n",
            "  \"episode\": 1,\n",
            "  \"category\": \"office\",\n",
            "  \"total_detections\": 86,\n",
            "  \"unique_emotions\": [\n",
            "    \"anger\",\n",
            "    \"disgust\",\n",
            "    \"fear\",\n",
            "    \"happy\",\n",
            "    \"neutral\",\n",
            "    \"sad\",\n",
            "    \"surprise\"\n",
            "  ]\n",
            "}\n",
            "\n",
            "First 5 emotions in sequence:\n",
            "  1. Timestamp 8.26s, Character 0: happy (confidence: 0.618)\n",
            "  2. Timestamp 9.01s, Character 0: happy (confidence: 0.696)\n",
            "  3. Timestamp 9.01s, Character 1: anger (confidence: 0.466)\n",
            "  4. Timestamp 9.76s, Character 1: anger (confidence: 0.687)\n",
            "  5. Timestamp 10.51s, Character 0: anger (confidence: 0.750)\n"
          ]
        }
      ],
      "source": [
        "# Create the main data structure: emotions in order of appearance per sketch\n",
        "emotions_by_sketch = {}\n",
        "\n",
        "# Process each sketch\n",
        "for sketch_id in sorted(df_sorted['sketch_id'].unique()):\n",
        "    sketch_data = df_sorted[df_sorted['sketch_id'] == sketch_id].copy()\n",
        "    \n",
        "    # Get sketch metadata (should be same for all rows of a sketch)\n",
        "    first_row = sketch_data.iloc[0]\n",
        "    \n",
        "    # Create ordered list of emotions with their positions\n",
        "    emotion_sequence = []\n",
        "    for idx, row in sketch_data.iterrows():\n",
        "        emotion_sequence.append({\n",
        "            'timestamp': float(row['timestamp']),\n",
        "            'frame_num': int(row['frame_num_in_episode']),\n",
        "            'character_id': int(row['character_id']),\n",
        "            'emotion': row['emotion'],\n",
        "            'confidence': float(row['confidence']),\n",
        "            'det_score': float(row['det_score'])\n",
        "        })\n",
        "    \n",
        "    # Store in dictionary\n",
        "    emotions_by_sketch[sketch_id] = {\n",
        "        'sketch_id': int(sketch_id),\n",
        "        'sketch_name': first_row.get('name', ''),\n",
        "        'season': int(first_row.get('season', 0)) if pd.notna(first_row.get('season', 0)) else 0,\n",
        "        'episode': int(first_row.get('episode', 0)) if pd.notna(first_row.get('episode', 0)) else 0,\n",
        "        'category': first_row.get('category', ''),\n",
        "        'category2': first_row.get('category2', ''),\n",
        "        'start_time': first_row.get('start', ''),\n",
        "        'end_time': first_row.get('end', ''),\n",
        "        'total_detections': len(emotion_sequence),\n",
        "        'emotion_sequence': emotion_sequence,  # Ordered list of emotions\n",
        "        'emotion_counts': sketch_data['emotion'].value_counts().to_dict(),  # Count of each emotion\n",
        "        'unique_emotions': sorted(sketch_data['emotion'].unique().tolist())  # Unique emotions in this sketch\n",
        "    }\n",
        "\n",
        "print(f\"Created data structure for {len(emotions_by_sketch)} sketches\")\n",
        "# Get first available sketch ID for example\n",
        "first_sketch_id = min(emotions_by_sketch.keys()) if emotions_by_sketch else None\n",
        "if first_sketch_id:\n",
        "    print(f\"\\nExample structure for sketch {first_sketch_id}:\")\n",
        "    example_keys = ['sketch_id', 'sketch_name', 'season', 'episode', 'category', 'total_detections', 'unique_emotions']\n",
        "    example_dict = {k: emotions_by_sketch[first_sketch_id][k] for k in example_keys}\n",
        "    print(json.dumps(example_dict, indent=2))\n",
        "    print(f\"\\nFirst 5 emotions in sequence:\")\n",
        "    for i, emo in enumerate(emotions_by_sketch[first_sketch_id]['emotion_sequence'][:5]):\n",
        "        print(f\"  {i+1}. Timestamp {emo['timestamp']:.2f}s, Character {emo['character_id']}: {emo['emotion']} (confidence: {emo['confidence']:.3f})\")\n",
        "else:\n",
        "    print(\"No sketches found in data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "a2720734",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created normalized position structure for 86 sketches\n",
            "\n",
            "Example normalized sequence for sketch 1 (first 5):\n",
            "  Position 0.000 (timestamp 8.26s): Character 0 - happy\n",
            "  Position 0.009 (timestamp 9.01s): Character 0 - happy\n",
            "  Position 0.009 (timestamp 9.01s): Character 1 - anger\n",
            "  Position 0.018 (timestamp 9.76s): Character 1 - anger\n",
            "  Position 0.026 (timestamp 10.51s): Character 0 - anger\n"
          ]
        }
      ],
      "source": [
        "# Create a normalized position-based structure for easier charting\n",
        "emotions_by_sketch_normalized = {}\n",
        "\n",
        "for sketch_id, data in emotions_by_sketch.items():\n",
        "    emotion_sequence_normalized = []\n",
        "    total = data['total_detections']\n",
        "    \n",
        "    # Get min and max timestamps for normalization\n",
        "    timestamps = [e['timestamp'] for e in data['emotion_sequence']]\n",
        "    min_ts = min(timestamps) if timestamps else 0\n",
        "    max_ts = max(timestamps) if timestamps else 1\n",
        "    ts_range = max_ts - min_ts if max_ts > min_ts else 1\n",
        "    \n",
        "    for emo in data['emotion_sequence']:\n",
        "        normalized_position = (emo['timestamp'] - min_ts) / ts_range  # 0.0 to 1.0\n",
        "        emotion_sequence_normalized.append({\n",
        "            'normalized_position': float(normalized_position),\n",
        "            'timestamp': emo['timestamp'],\n",
        "            'frame_num': emo['frame_num'],\n",
        "            'character_id': emo['character_id'],\n",
        "            'emotion': emo['emotion'],\n",
        "            'confidence': emo['confidence']\n",
        "        })\n",
        "    \n",
        "    emotions_by_sketch_normalized[sketch_id] = {\n",
        "        **{k: v for k, v in data.items() if k != 'emotion_sequence'},\n",
        "        'emotion_sequence_normalized': emotion_sequence_normalized\n",
        "    }\n",
        "\n",
        "print(f\"Created normalized position structure for {len(emotions_by_sketch_normalized)} sketches\")\n",
        "# Get first available sketch ID for example\n",
        "first_sketch_id = min(emotions_by_sketch_normalized.keys()) if emotions_by_sketch_normalized else None\n",
        "if first_sketch_id:\n",
        "    print(f\"\\nExample normalized sequence for sketch {first_sketch_id} (first 5):\")\n",
        "    for emo in emotions_by_sketch_normalized[first_sketch_id]['emotion_sequence_normalized'][:5]:\n",
        "        print(f\"  Position {emo['normalized_position']:.3f} (timestamp {emo['timestamp']:.2f}s): Character {emo['character_id']} - {emo['emotion']}\")\n",
        "else:\n",
        "    print(\"No sketches found in normalized data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "569852a7",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting DataFrame shape: (20603, 12)\n",
            "\n",
            "First 10 rows:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sketch_id</th>\n",
              "      <th>sketch_name</th>\n",
              "      <th>season</th>\n",
              "      <th>episode</th>\n",
              "      <th>category</th>\n",
              "      <th>category2</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>frame_num</th>\n",
              "      <th>normalized_position</th>\n",
              "      <th>character_id</th>\n",
              "      <th>emotion</th>\n",
              "      <th>confidence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Both Ways</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>office</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8.25825</td>\n",
              "      <td>198</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>happy</td>\n",
              "      <td>0.617962</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Both Ways</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>office</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9.00900</td>\n",
              "      <td>216</td>\n",
              "      <td>0.008772</td>\n",
              "      <td>0</td>\n",
              "      <td>happy</td>\n",
              "      <td>0.696091</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>Both Ways</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>office</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9.00900</td>\n",
              "      <td>216</td>\n",
              "      <td>0.008772</td>\n",
              "      <td>1</td>\n",
              "      <td>anger</td>\n",
              "      <td>0.465669</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>Both Ways</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>office</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9.75975</td>\n",
              "      <td>234</td>\n",
              "      <td>0.017544</td>\n",
              "      <td>1</td>\n",
              "      <td>anger</td>\n",
              "      <td>0.686593</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>Both Ways</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>office</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10.51050</td>\n",
              "      <td>252</td>\n",
              "      <td>0.026316</td>\n",
              "      <td>0</td>\n",
              "      <td>anger</td>\n",
              "      <td>0.749711</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>Both Ways</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>office</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10.51050</td>\n",
              "      <td>252</td>\n",
              "      <td>0.026316</td>\n",
              "      <td>1</td>\n",
              "      <td>anger</td>\n",
              "      <td>0.501236</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>Both Ways</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>office</td>\n",
              "      <td>NaN</td>\n",
              "      <td>11.26125</td>\n",
              "      <td>270</td>\n",
              "      <td>0.035088</td>\n",
              "      <td>0</td>\n",
              "      <td>sad</td>\n",
              "      <td>0.303702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>Both Ways</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>office</td>\n",
              "      <td>NaN</td>\n",
              "      <td>12.01200</td>\n",
              "      <td>288</td>\n",
              "      <td>0.043860</td>\n",
              "      <td>0</td>\n",
              "      <td>sad</td>\n",
              "      <td>0.673540</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>Both Ways</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>office</td>\n",
              "      <td>NaN</td>\n",
              "      <td>12.01200</td>\n",
              "      <td>288</td>\n",
              "      <td>0.043860</td>\n",
              "      <td>1</td>\n",
              "      <td>anger</td>\n",
              "      <td>0.560665</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>Both Ways</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>office</td>\n",
              "      <td>NaN</td>\n",
              "      <td>12.76275</td>\n",
              "      <td>306</td>\n",
              "      <td>0.052632</td>\n",
              "      <td>0</td>\n",
              "      <td>sad</td>\n",
              "      <td>0.736900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sketch_id sketch_name  season  episode category category2  timestamp  \\\n",
              "0          1   Both Ways       1        1   office       NaN    8.25825   \n",
              "1          1   Both Ways       1        1   office       NaN    9.00900   \n",
              "2          1   Both Ways       1        1   office       NaN    9.00900   \n",
              "3          1   Both Ways       1        1   office       NaN    9.75975   \n",
              "4          1   Both Ways       1        1   office       NaN   10.51050   \n",
              "5          1   Both Ways       1        1   office       NaN   10.51050   \n",
              "6          1   Both Ways       1        1   office       NaN   11.26125   \n",
              "7          1   Both Ways       1        1   office       NaN   12.01200   \n",
              "8          1   Both Ways       1        1   office       NaN   12.01200   \n",
              "9          1   Both Ways       1        1   office       NaN   12.76275   \n",
              "\n",
              "   frame_num  normalized_position  character_id emotion  confidence  \n",
              "0        198             0.000000             0   happy    0.617962  \n",
              "1        216             0.008772             0   happy    0.696091  \n",
              "2        216             0.008772             1   anger    0.465669  \n",
              "3        234             0.017544             1   anger    0.686593  \n",
              "4        252             0.026316             0   anger    0.749711  \n",
              "5        252             0.026316             1   anger    0.501236  \n",
              "6        270             0.035088             0     sad    0.303702  \n",
              "7        288             0.043860             0     sad    0.673540  \n",
              "8        288             0.043860             1   anger    0.560665  \n",
              "9        306             0.052632             0     sad    0.736900  "
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a long-format DataFrame for easier plotting\n",
        "plotting_data = []\n",
        "\n",
        "for sketch_id, data in emotions_by_sketch.items():\n",
        "    timestamps = [e['timestamp'] for e in data['emotion_sequence']]\n",
        "    min_ts = min(timestamps) if timestamps else 0\n",
        "    max_ts = max(timestamps) if timestamps else 1\n",
        "    ts_range = max_ts - min_ts if max_ts > min_ts else 1\n",
        "    \n",
        "    for emo in data['emotion_sequence']:\n",
        "        normalized_position = (emo['timestamp'] - min_ts) / ts_range\n",
        "        plotting_data.append({\n",
        "            'sketch_id': data['sketch_id'],\n",
        "            'sketch_name': data['sketch_name'],\n",
        "            'season': data['season'],\n",
        "            'episode': data['episode'],\n",
        "            'category': data['category'],\n",
        "            'category2': data['category2'],\n",
        "            'timestamp': emo['timestamp'],\n",
        "            'frame_num': emo['frame_num'],\n",
        "            'normalized_position': normalized_position,\n",
        "            'character_id': emo['character_id'],\n",
        "            'emotion': emo['emotion'],\n",
        "            'confidence': emo['confidence']\n",
        "        })\n",
        "\n",
        "df_emotions_plotting = pd.DataFrame(plotting_data)\n",
        "\n",
        "print(f\"Plotting DataFrame shape: {df_emotions_plotting.shape}\")\n",
        "print(f\"\\nFirst 10 rows:\")\n",
        "df_emotions_plotting.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "4a500ae8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Summary DataFrame shape: (86, 11)\n",
            "\n",
            "First few sketches:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sketch_id</th>\n",
              "      <th>sketch_name</th>\n",
              "      <th>season</th>\n",
              "      <th>episode</th>\n",
              "      <th>total_detections</th>\n",
              "      <th>num_unique_emotions</th>\n",
              "      <th>emotion_string</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Both Ways</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>86</td>\n",
              "      <td>7</td>\n",
              "      <td>happy -&gt; happy -&gt; anger -&gt; anger -&gt; anger -&gt; a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Has This Ever Happened to You?</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>126</td>\n",
              "      <td>7</td>\n",
              "      <td>neutral -&gt; disgust -&gt; disgust -&gt; surprise -&gt; h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Baby of the Year</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>291</td>\n",
              "      <td>7</td>\n",
              "      <td>sad -&gt; neutral -&gt; sad -&gt; sad -&gt; disgust -&gt; ang...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Instagram</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>139</td>\n",
              "      <td>6</td>\n",
              "      <td>happy -&gt; happy -&gt; happy -&gt; happy -&gt; happy -&gt; h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Gift Receipt</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>517</td>\n",
              "      <td>7</td>\n",
              "      <td>sad -&gt; sad -&gt; neutral -&gt; happy -&gt; happy -&gt; hap...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>Biker Guy</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>152</td>\n",
              "      <td>7</td>\n",
              "      <td>happy -&gt; happy -&gt; sad -&gt; sad -&gt; neutral -&gt; sad...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>River Mountain High</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>174</td>\n",
              "      <td>6</td>\n",
              "      <td>happy -&gt; happy -&gt; happy -&gt; happy -&gt; happy -&gt; h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>Wilson's Toupees</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>157</td>\n",
              "      <td>7</td>\n",
              "      <td>surprise -&gt; happy -&gt; happy -&gt; happy -&gt; happy -...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>Pink Bag</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>323</td>\n",
              "      <td>7</td>\n",
              "      <td>happy -&gt; happy -&gt; happy -&gt; surprise -&gt; sad -&gt; ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>River Mountain High</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>92</td>\n",
              "      <td>7</td>\n",
              "      <td>disgust -&gt; surprise -&gt; neutral -&gt; neutral -&gt; s...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sketch_id                     sketch_name  season  episode  \\\n",
              "0          1                       Both Ways       1        1   \n",
              "1          2  Has This Ever Happened to You?       1        1   \n",
              "2          3                Baby of the Year       1        1   \n",
              "3          4                       Instagram       1        1   \n",
              "4          5                    Gift Receipt       1        1   \n",
              "5          6                       Biker Guy       1        2   \n",
              "6          7             River Mountain High       1        2   \n",
              "7          8                Wilson's Toupees       1        2   \n",
              "8          9                        Pink Bag       1        2   \n",
              "9         10             River Mountain High       1        2   \n",
              "\n",
              "   total_detections  num_unique_emotions  \\\n",
              "0                86                    7   \n",
              "1               126                    7   \n",
              "2               291                    7   \n",
              "3               139                    6   \n",
              "4               517                    7   \n",
              "5               152                    7   \n",
              "6               174                    6   \n",
              "7               157                    7   \n",
              "8               323                    7   \n",
              "9                92                    7   \n",
              "\n",
              "                                      emotion_string  \n",
              "0  happy -> happy -> anger -> anger -> anger -> a...  \n",
              "1  neutral -> disgust -> disgust -> surprise -> h...  \n",
              "2  sad -> neutral -> sad -> sad -> disgust -> ang...  \n",
              "3  happy -> happy -> happy -> happy -> happy -> h...  \n",
              "4  sad -> sad -> neutral -> happy -> happy -> hap...  \n",
              "5  happy -> happy -> sad -> sad -> neutral -> sad...  \n",
              "6  happy -> happy -> happy -> happy -> happy -> h...  \n",
              "7  surprise -> happy -> happy -> happy -> happy -...  \n",
              "8  happy -> happy -> happy -> surprise -> sad -> ...  \n",
              "9  disgust -> surprise -> neutral -> neutral -> s...  "
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a summary DataFrame for easier analysis\n",
        "sketch_summaries = []\n",
        "\n",
        "for sketch_id, data in emotions_by_sketch.items():\n",
        "    # Create a simple list of emotions in order\n",
        "    emotion_list = [e['emotion'] for e in data['emotion_sequence']]\n",
        "    \n",
        "    sketch_summaries.append({\n",
        "        'sketch_id': data['sketch_id'],\n",
        "        'sketch_name': data['sketch_name'],\n",
        "        'season': data['season'],\n",
        "        'episode': data['episode'],\n",
        "        'category': data['category'],\n",
        "        'category2': data['category2'],\n",
        "        'total_detections': data['total_detections'],\n",
        "        'num_unique_emotions': len(data['unique_emotions']),\n",
        "        'emotion_sequence': emotion_list,  # List of emotions in order\n",
        "        'emotion_string': ' -> '.join(emotion_list),  # String representation for quick viewing\n",
        "        'emotion_counts': data['emotion_counts']\n",
        "    })\n",
        "\n",
        "df_sketch_emotions_summary = pd.DataFrame(sketch_summaries)\n",
        "\n",
        "print(f\"Summary DataFrame shape: {df_sketch_emotions_summary.shape}\")\n",
        "print(f\"\\nFirst few sketches:\")\n",
        "df_sketch_emotions_summary[['sketch_id', 'sketch_name', 'season', 'episode', 'total_detections', 'num_unique_emotions', 'emotion_string']].head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "3f22aaa2",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "DATA STRUCTURE STATISTICS\n",
            "============================================================\n",
            "\n",
            "Total sketches: 86\n",
            "Total emotion detections: 20603\n",
            "Total unique emotions: 7\n",
            "\n",
            "All 7 emotions:\n",
            "   1. anger\n",
            "   2. disgust\n",
            "   3. fear\n",
            "   4. happy\n",
            "   5. neutral\n",
            "   6. sad\n",
            "   7. surprise\n",
            "\n",
            "\n",
            "Sketches by season:\n",
            "season\n",
            "1    31\n",
            "2    28\n",
            "3    27\n",
            "Name: sketch_id, dtype: int64\n",
            "\n",
            "\n",
            "Sketches by episode:\n",
            "season  episode\n",
            "1       1          5\n",
            "        2          6\n",
            "        3          5\n",
            "        4          4\n",
            "        5          5\n",
            "        6          6\n",
            "2       1          5\n",
            "        2          5\n",
            "        3          5\n",
            "        4          3\n",
            "        5          5\n",
            "        6          5\n",
            "3       1          5\n",
            "        2          5\n",
            "        3          5\n",
            "        4          5\n",
            "        5          3\n",
            "        6          4\n",
            "Name: sketch_id, dtype: int64\n",
            "\n",
            "\n",
            "Average detections per sketch:\n",
            "  Mean: 239.6\n",
            "  Median: 211.5\n",
            "  Min: 13\n",
            "  Max: 677\n",
            "\n",
            "\n",
            "Emotion distribution across all sketches:\n",
            "emotion\n",
            "neutral     5688\n",
            "sad         4748\n",
            "happy       4726\n",
            "surprise    1750\n",
            "anger       1559\n",
            "disgust     1492\n",
            "fear         640\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Display statistics about the data structure\n",
        "print(\"=\" * 60)\n",
        "print(\"DATA STRUCTURE STATISTICS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(f\"\\nTotal sketches: {len(emotions_by_sketch)}\")\n",
        "print(f\"Total emotion detections: {len(df_emotions_plotting)}\")\n",
        "print(f\"Total unique emotions: {len(all_emotions)}\")\n",
        "print(f\"\\nAll {len(all_emotions)} emotions:\")\n",
        "for i, emo in enumerate(all_emotions, 1):\n",
        "    print(f\"  {i:2d}. {emo}\")\n",
        "\n",
        "if 'season' in df_emotions_plotting.columns:\n",
        "    print(f\"\\n\\nSketches by season:\")\n",
        "    print(df_emotions_plotting.groupby('season')['sketch_id'].nunique())\n",
        "\n",
        "    print(f\"\\n\\nSketches by episode:\")\n",
        "    episode_counts = df_emotions_plotting.groupby(['season', 'episode'])['sketch_id'].nunique()\n",
        "    print(episode_counts)\n",
        "\n",
        "print(f\"\\n\\nAverage detections per sketch:\")\n",
        "detections_per_sketch = df_emotions_plotting.groupby('sketch_id').size()\n",
        "print(f\"  Mean: {detections_per_sketch.mean():.1f}\")\n",
        "print(f\"  Median: {detections_per_sketch.median():.1f}\")\n",
        "print(f\"  Min: {detections_per_sketch.min()}\")\n",
        "print(f\"  Max: {detections_per_sketch.max()}\")\n",
        "\n",
        "print(f\"\\n\\nEmotion distribution across all sketches:\")\n",
        "emotion_counts = df_emotions_plotting['emotion'].value_counts()\n",
        "print(emotion_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92bba5d4",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data structures saved:\n",
            "  ✓ facial_emotions_by_sketch_structured.json: Full structured data\n",
            "  ✓ facial_emotions_by_sketch_normalized.json: Normalized position data\n",
            "  ✓ facial_emotions_plotting_data.csv: Long-format DataFrame for plotting\n",
            "  ✓ facial_emotions_by_sketch_summary.csv: Summary DataFrame\n",
            "  ✓ facial_emotions_heatmap_all.csv: All emotions heatmap data\n",
            "  ✓ facial_emotions_heatmap_dominant.csv: Dominant emotions heatmap data\n",
            "  ✓ facial_emotions_heatmap_scores.csv: Score-based heatmap data\n"
          ]
        }
      ],
      "source": [
        "# Save the data structures for later use\n",
        "# Helper function to convert numpy types to native Python types for JSON serialization\n",
        "def convert_to_json_serializable(obj):\n",
        "    \"\"\"Recursively convert numpy types to native Python types\"\"\"\n",
        "    if isinstance(obj, dict):\n",
        "        result = {}\n",
        "        for k, v in obj.items():\n",
        "            if isinstance(k, (np.integer, np.int64, np.int32)):\n",
        "                key = int(k)\n",
        "            else:\n",
        "                key = k\n",
        "            result[key] = convert_to_json_serializable(v)\n",
        "        return result\n",
        "    elif isinstance(obj, list):\n",
        "        return [convert_to_json_serializable(item) for item in obj]\n",
        "    elif isinstance(obj, (np.integer, np.int64, np.int32)):\n",
        "        return int(obj)\n",
        "    elif isinstance(obj, (np.floating, np.float64, np.float32)):\n",
        "        return float(obj)\n",
        "    elif isinstance(obj, np.ndarray):\n",
        "        return obj.tolist()\n",
        "    elif pd.isna(obj):\n",
        "        return None\n",
        "    else:\n",
        "        return obj\n",
        "\n",
        "# 1. Full structured data (JSON)\n",
        "emotions_by_sketch_json = convert_to_json_serializable(emotions_by_sketch)\n",
        "with open('facial_emotions_by_sketch_structured.json', 'w') as f:\n",
        "    json.dump(emotions_by_sketch_json, f, indent=2)\n",
        "\n",
        "# 2. Normalized version (JSON)\n",
        "emotions_by_sketch_normalized_json = convert_to_json_serializable(emotions_by_sketch_normalized)\n",
        "with open('facial_emotions_by_sketch_normalized.json', 'w') as f:\n",
        "    json.dump(emotions_by_sketch_normalized_json, f, indent=2)\n",
        "\n",
        "# 3. Plotting DataFrame (CSV)\n",
        "df_emotions_plotting.to_csv('facial_emotions_plotting_data.csv', index=False)\n",
        "\n",
        "# 4. Summary DataFrame (CSV)\n",
        "df_sketch_emotions_export = df_sketch_emotions_summary.copy()\n",
        "df_sketch_emotions_export['emotion_sequence'] = df_sketch_emotions_export['emotion_sequence'].apply(lambda x: '|'.join(x))\n",
        "df_sketch_emotions_export.to_csv('facial_emotions_by_sketch_summary.csv', index=False)\n",
        "\n",
        "# 5. Export heatmap data\n",
        "heatmap_all_final.to_csv('facial_emotions_heatmap_all.csv', index=False)\n",
        "heatmap_final.to_csv('facial_emotions_heatmap_dominant.csv', index=False)\n",
        "heatmap_score_final.to_csv('facial_emotions_heatmap_scores.csv', index=False)\n",
        "\n",
        "print(\"Data structures saved:\")\n",
        "print(\"  ✓ facial_emotions_by_sketch_structured.json: Full structured data\")\n",
        "print(\"  ✓ facial_emotions_by_sketch_normalized.json: Normalized position data\")\n",
        "print(\"  ✓ facial_emotions_plotting_data.csv: Long-format DataFrame for plotting\")\n",
        "print(\"  ✓ facial_emotions_by_sketch_summary.csv: Summary DataFrame\")\n",
        "print(\"  ✓ facial_emotions_heatmap_all.csv: All emotions heatmap data\")\n",
        "print(\"  ✓ facial_emotions_heatmap_dominant.csv: Dominant emotions heatmap data\")\n",
        "print(\"  ✓ facial_emotions_heatmap_scores.csv: Score-based heatmap data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a756937c",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv (3.13.5)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
