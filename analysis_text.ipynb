{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a50040b0",
      "metadata": {},
      "source": [
        "### Examining the transcripts sentiment results\n",
        "\n",
        "I used the GoEmotions model for [text classification](https://colab.research.google.com/drive/1GuUbnw1pVMQrNDVKJ98bJGYvR3YWWB_D) to assign an emotion to each sentence. This notebook analyzes the results and the transcripts themselves.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "bf5e484d",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "from collections import defaultdict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "a8ad12b3",
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv('results_text_sentiments.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "4ed630d7",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 6509 entries, 0 to 6508\n",
            "Data columns (total 8 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   sketch_id        6509 non-null   int64  \n",
            " 1   sketch_name      6509 non-null   object \n",
            " 2   season           6509 non-null   int64  \n",
            " 3   episode          6509 non-null   int64  \n",
            " 4   sentence_index   6509 non-null   int64  \n",
            " 5   sentence_text    6509 non-null   object \n",
            " 6   sentiment_label  6509 non-null   object \n",
            " 7   sentiment_score  6509 non-null   float64\n",
            "dtypes: float64(1), int64(4), object(3)\n",
            "memory usage: 406.9+ KB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4795c93a",
      "metadata": {},
      "source": [
        "## Analysis Ideas\n",
        "\n",
        "### 1. **Sentiment Distribution & Patterns**\n",
        "- Overall sentiment distribution across all sketches\n",
        "- Sentiment by sketch category (office, commercial, party, etc.)\n",
        "- Sentiment by season/episode (evolution over time)\n",
        "- Most emotional vs. most neutral sketches\n",
        "- Sentiment score distributions (high vs. low confidence)\n",
        "\n",
        "### 2. **Temporal Analysis**\n",
        "- Sentiment evolution within sketches (beginning → middle → end)\n",
        "- Sentiment transitions between consecutive sentences\n",
        "- Sentiment patterns by sentence position (first 25%, middle 50%, last 25%)\n",
        "- Episode-level sentiment arcs\n",
        "\n",
        "### 6. **Visualization Ideas for Observable Plot**\n",
        "- **Heatmap**: Sentiment by category × emotion type\n",
        "- **Line chart**: Sentiment evolution across seasons/episodes\n",
        "- **Bar chart**: Top emotions by category\n",
        "- **Streamgraph**: Sentiment flow within a sketch\n",
        "- **Scatter plot**: Sentiment score vs. sentence position\n",
        "- **Network graph**: Sentiment transitions between emotions\n",
        "- **Radar chart**: Emotion profile by category\n",
        "- **Timeline**: Sentiment arc for a specific sketch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "3c0b00b1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total sentences: 6509\n",
            "Total sketches: 86\n",
            "Total episodes: 18\n",
            "Total seasons: 3\n",
            "\n",
            "Unique emotions: 25\n",
            "Unique categories: 22\n"
          ]
        }
      ],
      "source": [
        "# Load metadata\n",
        "metadata = pd.read_csv('episode_metadata.csv')\n",
        "\n",
        "# Merge sentiment data with metadata\n",
        "df_merged = df.merge(metadata, left_on='sketch_id', right_on='id', how='left')\n",
        "\n",
        "# Basic stats\n",
        "print(f\"Total sentences: {len(df)}\")\n",
        "print(f\"Total sketches: {df['sketch_id'].nunique()}\")\n",
        "print(f\"Total episodes: {df.groupby(['season', 'episode']).ngroups}\")\n",
        "print(f\"Total seasons: {df['season'].nunique()}\")\n",
        "print(f\"\\nUnique emotions: {df['sentiment_label'].nunique()}\")\n",
        "print(f\"Unique categories: {df_merged['category'].nunique()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "49539700",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>percentage</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sentiment_label</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>neutral</th>\n",
              "      <td>3718</td>\n",
              "      <td>57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>curiosity</th>\n",
              "      <td>510</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>approval</th>\n",
              "      <td>368</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>anger</th>\n",
              "      <td>333</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>admiration</th>\n",
              "      <td>268</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>disapproval</th>\n",
              "      <td>199</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>confusion</th>\n",
              "      <td>135</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>surprise</th>\n",
              "      <td>113</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>annoyance</th>\n",
              "      <td>107</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gratitude</th>\n",
              "      <td>80</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sadness</th>\n",
              "      <td>77</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>joy</th>\n",
              "      <td>67</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>caring</th>\n",
              "      <td>67</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>love</th>\n",
              "      <td>66</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>amusement</th>\n",
              "      <td>66</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>excitement</th>\n",
              "      <td>61</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>remorse</th>\n",
              "      <td>52</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>desire</th>\n",
              "      <td>48</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>optimism</th>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>disappointment</th>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fear</th>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>disgust</th>\n",
              "      <td>25</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>realization</th>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>embarrassment</th>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nervousness</th>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 count  percentage\n",
              "sentiment_label                   \n",
              "neutral           3718          57\n",
              "curiosity          510           8\n",
              "approval           368           6\n",
              "anger              333           5\n",
              "admiration         268           4\n",
              "disapproval        199           3\n",
              "confusion          135           2\n",
              "surprise           113           2\n",
              "annoyance          107           2\n",
              "gratitude           80           1\n",
              "sadness             77           1\n",
              "joy                 67           1\n",
              "caring              67           1\n",
              "love                66           1\n",
              "amusement           66           1\n",
              "excitement          61           1\n",
              "remorse             52           1\n",
              "desire              48           1\n",
              "optimism            41           1\n",
              "disappointment      32           0\n",
              "fear                31           0\n",
              "disgust             25           0\n",
              "realization         18           0\n",
              "embarrassment       14           0\n",
              "nervousness         13           0"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 1. Overall sentiment distribution\n",
        "sentiment_counts = df['sentiment_label'].value_counts()\n",
        "sentiment_percentages = sentiment_counts / sentiment_counts.sum() * 100\n",
        "sentiment_distribution = pd.DataFrame({\n",
        "    'count': sentiment_counts,\n",
        "    'percentage': sentiment_percentages\n",
        "})\n",
        "sentiment_distribution['percentage'] = sentiment_distribution['percentage'].round(0).astype(int)\n",
        "sentiment_distribution.to_csv('overall_sentiment_distribution.csv')\n",
        "sentiment_distribution\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2386711",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>percentage</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>simplified_label</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>happy</th>\n",
              "      <td>10</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>surprise</th>\n",
              "      <td>4</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sad</th>\n",
              "      <td>4</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fear</th>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>anger</th>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>disgust</th>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>neutral</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  count  percentage\n",
              "simplified_label                   \n",
              "happy                10          40\n",
              "surprise              4          16\n",
              "sad                   4          16\n",
              "fear                  2           8\n",
              "anger                 2           8\n",
              "disgust               2           8\n",
              "neutral               1           4"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Bring in the externally edited overall_sentiment_distribution.csv\n",
        "overall_sentiment_distribution = pd.read_csv('overall_sentiment_distribution.csv')\n",
        "overall_sentiment_distribution\n",
        "# Recalculate sentiment distribution using the 'simplified_label' column from the externally edited csv\n",
        "simplified_sentiment_counts = overall_sentiment_distribution['simplified_label'].value_counts()\n",
        "simplified_sentiment_percentages = simplified_sentiment_counts / simplified_sentiment_counts.sum() * 100\n",
        "\n",
        "simplified_sentiment_distribution = pd.DataFrame({\n",
        "    'count': simplified_sentiment_counts,\n",
        "    'percentage': simplified_sentiment_percentages.round(0).astype(int)\n",
        "})\n",
        "\n",
        "simplified_sentiment_distribution\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "9b06fdb7",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top 5 emotions by category:\n",
            "    category sentiment_label  count  total  percentage\n",
            "12     class         neutral     45     95   47.368421\n",
            "5      class       curiosity     12     95   12.631579\n",
            "0      class           anger     10     95   10.526316\n",
            "4      class       confusion      5     95    5.263158\n",
            "8      class         disgust      5     95    5.263158\n",
            "..       ...             ...    ...    ...         ...\n",
            "365     tour         neutral     41     85   48.235294\n",
            "357     tour        approval      9     85   10.588235\n",
            "355     tour           anger      5     85    5.882353\n",
            "361     tour     disapproval      5     85    5.882353\n",
            "354     tour      admiration      4     85    4.705882\n",
            "\n",
            "[110 rows x 5 columns]\n"
          ]
        }
      ],
      "source": [
        "# 2. Sentiment by category\n",
        "if 'category' in df_merged.columns:\n",
        "    category_sentiment = df_merged.groupby(['category', 'sentiment_label']).size().reset_index(name='count')\n",
        "    category_totals = df_merged.groupby('category').size()\n",
        "    \n",
        "    # Calculate percentages\n",
        "    category_sentiment_pct = category_sentiment.merge(\n",
        "        category_totals.reset_index(name='total'), \n",
        "        on='category'\n",
        "    )\n",
        "    category_sentiment_pct['percentage'] = (category_sentiment_pct['count'] / category_sentiment_pct['total']) * 100\n",
        "    \n",
        "    # Top emotions per category\n",
        "    top_emotions_by_category = category_sentiment_pct.sort_values(['category', 'count'], ascending=[True, False]).groupby('category').head(5)\n",
        "    print(\"Top 5 emotions by category:\")\n",
        "    print(top_emotions_by_category)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "3be07888",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exported top_emotions_by_category.csv\n"
          ]
        }
      ],
      "source": [
        "top_emotions_by_category.to_csv('top_emotions_by_category.csv', index=False)\n",
        "print(f\"Exported top_emotions_by_category.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa63a6ed",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>count_of_category</th>\n",
              "      <th>count_of_category2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>office</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>commercial</td>\n",
              "      <td>15</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>party</td>\n",
              "      <td>13</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>game show</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>driving</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>restaurant</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>reality tv</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>family</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>dating</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>sci-fi/fantasy</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>tour</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>funeral</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>social media</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>live sitcom taping</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>class</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>revenge</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>movie press junket</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>magic show</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>movie trailer</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>theatre</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>music</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>kids</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>legal trial</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              category  count_of_category  count_of_category2\n",
              "0               office                 20                   1\n",
              "1           commercial                 15                   2\n",
              "2                party                 13                   3\n",
              "3            game show                  5                   0\n",
              "4              driving                  5                   1\n",
              "5           restaurant                  4                   4\n",
              "6           reality tv                  4                   0\n",
              "7               family                  3                   0\n",
              "8               dating                  3                   2\n",
              "9       sci-fi/fantasy                  2                   0\n",
              "10                tour                  1                   0\n",
              "11             funeral                  1                   2\n",
              "12        social media                  1                   1\n",
              "13  live sitcom taping                  1                   0\n",
              "14               class                  1                   0\n",
              "15             revenge                  1                   0\n",
              "16  movie press junket                  1                   0\n",
              "17          magic show                  1                   0\n",
              "18       movie trailer                  1                   0\n",
              "19             theatre                  1                   0\n",
              "20               music                  1                   0\n",
              "21                kids                  1                   0\n",
              "22         legal trial                  0                   1"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# categori counts\n",
        "\n",
        "cat1_counts = metadata['category'].value_counts(dropna=True)\n",
        "cat2_counts = metadata['category2'].value_counts(dropna=True)\n",
        "\n",
        "# count categories from both columns\n",
        "all_categories = set(cat1_counts.index).union(set(cat2_counts.index))\n",
        "all_categories = [cat for cat in all_categories if pd.notna(cat)]\n",
        "\n",
        "# summary table\n",
        "summary_data = []\n",
        "for cat in all_categories:\n",
        "    count_primary = cat1_counts.get(cat, 0)\n",
        "    count_secondary = cat2_counts.get(cat, 0)\n",
        "    summary_data.append({\n",
        "        'category': cat,\n",
        "        'count_of_category': count_primary,\n",
        "        'count_of_category2': count_secondary\n",
        "    })\n",
        "\n",
        "categories_table = pd.DataFrame(summary_data)\n",
        "categories_table = categories_table.sort_values(by='count_of_category', ascending=False).reset_index(drop=True)\n",
        "\n",
        "categories_table\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "380f232e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentiment distribution by season:\n",
            "    season sentiment_label  count  total  percentage\n",
            "19       1         neutral   1165   2080   56.009615\n",
            "7        1       curiosity    179   2080    8.605769\n",
            "4        1        approval    121   2080    5.817308\n",
            "0        1      admiration    105   2080    5.048077\n",
            "2        1           anger     83   2080    3.990385\n",
            "44       2         neutral   1242   2157   57.579972\n",
            "32       2       curiosity    157   2157    7.278628\n",
            "27       2           anger    117   2157    5.424200\n",
            "29       2        approval    111   2157    5.146036\n",
            "35       2     disapproval     85   2157    3.940658\n",
            "69       3         neutral   1311   2272   57.702465\n",
            "57       3       curiosity    174   2272    7.658451\n",
            "54       3        approval    136   2272    5.985915\n",
            "52       3           anger    133   2272    5.853873\n",
            "50       3      admiration     82   2272    3.609155\n"
          ]
        }
      ],
      "source": [
        "# 3. Sentiment by season\n",
        "season_sentiment = df.groupby(['season', 'sentiment_label']).size().reset_index(name='count')\n",
        "season_totals = df.groupby('season').size()\n",
        "\n",
        "season_sentiment_pct = season_sentiment.merge(\n",
        "    season_totals.reset_index(name='total'),\n",
        "    on='season'\n",
        ")\n",
        "season_sentiment_pct['percentage'] = (season_sentiment_pct['count'] / season_sentiment_pct['total']) * 100\n",
        "\n",
        "print(\"Sentiment distribution by season:\")\n",
        "print(season_sentiment_pct.sort_values(['season', 'count'], ascending=[True, False]).groupby('season').head(5))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "6cf0df3c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentiment by position in sketch:\n",
            "   position_bin sentiment_label  count\n",
            "19    beginning         neutral    950\n",
            "7     beginning       curiosity    125\n",
            "0     beginning      admiration    102\n",
            "4     beginning        approval    101\n",
            "2     beginning           anger     54\n",
            "44       middle         neutral   1862\n",
            "32       middle       curiosity    257\n",
            "29       middle        approval    187\n",
            "27       middle           anger    183\n",
            "25       middle      admiration    118\n",
            "69          end         neutral    906\n",
            "57          end       curiosity    128\n",
            "52          end           anger     96\n",
            "54          end        approval     80\n",
            "60          end     disapproval     66\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/hh/gv6hw42j5x72r3w36vz87jk00000gn/T/ipykernel_41364/2366376205.py:13: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
            "  position_sentiment = df.groupby(['position_bin', 'sentiment_label']).size().reset_index(name='count')\n",
            "/var/folders/hh/gv6hw42j5x72r3w36vz87jk00000gn/T/ipykernel_41364/2366376205.py:15: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
            "  print(position_sentiment.sort_values(['position_bin', 'count'], ascending=[True, False]).groupby('position_bin').head(5))\n"
          ]
        }
      ],
      "source": [
        "# 4. Sentiment evolution within sketches\n",
        "# Calculate relative position in sketch (0-1)\n",
        "sketch_lengths = df.groupby('sketch_id').size()\n",
        "df['sketch_length'] = df['sketch_id'].map(sketch_lengths)\n",
        "df['relative_position'] = (df['sentence_index'] - 1) / (df['sketch_length'] - 1)\n",
        "\n",
        "# Bin into beginning, middle, end\n",
        "df['position_bin'] = pd.cut(df['relative_position'], \n",
        "                            bins=[0, 0.25, 0.75, 1.0], \n",
        "                            labels=['beginning', 'middle', 'end'],\n",
        "                            include_lowest=True)\n",
        "\n",
        "position_sentiment = df.groupby(['position_bin', 'sentiment_label']).size().reset_index(name='count')\n",
        "print(\"Sentiment by position in sketch:\")\n",
        "print(position_sentiment.sort_values(['position_bin', 'count'], ascending=[True, False]).groupby('position_bin').head(5))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "3f7b3769",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>position_bin</th>\n",
              "      <th>sentiment_label</th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>beginning</td>\n",
              "      <td>admiration</td>\n",
              "      <td>102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>beginning</td>\n",
              "      <td>amusement</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>beginning</td>\n",
              "      <td>anger</td>\n",
              "      <td>54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>beginning</td>\n",
              "      <td>annoyance</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>beginning</td>\n",
              "      <td>approval</td>\n",
              "      <td>101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>end</td>\n",
              "      <td>optimism</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>end</td>\n",
              "      <td>realization</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>end</td>\n",
              "      <td>remorse</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>end</td>\n",
              "      <td>sadness</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>end</td>\n",
              "      <td>surprise</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>75 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   position_bin sentiment_label  count\n",
              "0     beginning      admiration    102\n",
              "1     beginning       amusement     12\n",
              "2     beginning           anger     54\n",
              "3     beginning       annoyance     16\n",
              "4     beginning        approval    101\n",
              "..          ...             ...    ...\n",
              "70          end        optimism     12\n",
              "71          end     realization      4\n",
              "72          end         remorse     11\n",
              "73          end         sadness     22\n",
              "74          end        surprise     28\n",
              "\n",
              "[75 rows x 3 columns]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "position_sentiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be0c248a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Most emotional sketches (top 10) as DataFrame:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sketch_id</th>\n",
              "      <th>sketch_name</th>\n",
              "      <th>category</th>\n",
              "      <th>pct_neutral</th>\n",
              "      <th>avg_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>28</td>\n",
              "      <td>Bozo #1</td>\n",
              "      <td>office</td>\n",
              "      <td>0.346154</td>\n",
              "      <td>0.807639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>53</td>\n",
              "      <td>Dave Campor</td>\n",
              "      <td>commercial</td>\n",
              "      <td>0.363636</td>\n",
              "      <td>0.741398</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>43</td>\n",
              "      <td>Detective Crashmore Trailer</td>\n",
              "      <td>movie trailer</td>\n",
              "      <td>0.390244</td>\n",
              "      <td>0.720090</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>50</td>\n",
              "      <td>Parking Lot</td>\n",
              "      <td>driving</td>\n",
              "      <td>0.413793</td>\n",
              "      <td>0.732421</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Both Ways</td>\n",
              "      <td>office</td>\n",
              "      <td>0.421053</td>\n",
              "      <td>0.836869</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>Pink Bag</td>\n",
              "      <td>office</td>\n",
              "      <td>0.421875</td>\n",
              "      <td>0.669075</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>76</td>\n",
              "      <td>Pacific Proposal Park</td>\n",
              "      <td>commercial</td>\n",
              "      <td>0.425000</td>\n",
              "      <td>0.759125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>74</td>\n",
              "      <td>Rat Mom</td>\n",
              "      <td>office</td>\n",
              "      <td>0.426829</td>\n",
              "      <td>0.709768</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>62</td>\n",
              "      <td>Summer Loving</td>\n",
              "      <td>reality tv</td>\n",
              "      <td>0.431373</td>\n",
              "      <td>0.705040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>48</td>\n",
              "      <td>Friends Weekend</td>\n",
              "      <td>party</td>\n",
              "      <td>0.442857</td>\n",
              "      <td>0.729108</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    sketch_id                  sketch_name       category  pct_neutral  \\\n",
              "27         28                      Bozo #1         office     0.346154   \n",
              "52         53                  Dave Campor     commercial     0.363636   \n",
              "42         43  Detective Crashmore Trailer  movie trailer     0.390244   \n",
              "49         50                  Parking Lot        driving     0.413793   \n",
              "0           1                    Both Ways         office     0.421053   \n",
              "8           9                     Pink Bag         office     0.421875   \n",
              "75         76        Pacific Proposal Park     commercial     0.425000   \n",
              "73         74                      Rat Mom         office     0.426829   \n",
              "61         62                Summer Loving     reality tv     0.431373   \n",
              "47         48              Friends Weekend          party     0.442857   \n",
              "\n",
              "    avg_score  \n",
              "27   0.807639  \n",
              "52   0.741398  \n",
              "42   0.720090  \n",
              "49   0.732421  \n",
              "0    0.836869  \n",
              "8    0.669075  \n",
              "75   0.759125  \n",
              "73   0.709768  \n",
              "61   0.705040  \n",
              "47   0.729108  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Most neutral sketches (top 10) as DataFrame:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sketch_id</th>\n",
              "      <th>sketch_name</th>\n",
              "      <th>category</th>\n",
              "      <th>pct_neutral</th>\n",
              "      <th>avg_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>65</td>\n",
              "      <td>Supermarket Swap VR Edition</td>\n",
              "      <td>game show</td>\n",
              "      <td>0.810127</td>\n",
              "      <td>0.762706</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>78</td>\n",
              "      <td>Summer Loving Pt. 2</td>\n",
              "      <td>dating</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.903059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Has This Ever Happened To You</td>\n",
              "      <td>commercial</td>\n",
              "      <td>0.727273</td>\n",
              "      <td>0.750548</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>24</td>\n",
              "      <td>The Day Robert Palin's Murdered Me</td>\n",
              "      <td>music</td>\n",
              "      <td>0.724638</td>\n",
              "      <td>0.801930</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>33</td>\n",
              "      <td>Coffin Flop</td>\n",
              "      <td>commercial</td>\n",
              "      <td>0.722222</td>\n",
              "      <td>0.759734</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>57</td>\n",
              "      <td>Tammy Craps</td>\n",
              "      <td>commercial</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.791690</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>32</td>\n",
              "      <td>Lunch Meeting</td>\n",
              "      <td>office</td>\n",
              "      <td>0.711111</td>\n",
              "      <td>0.697896</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>49</td>\n",
              "      <td>Calico Cut Pants</td>\n",
              "      <td>office</td>\n",
              "      <td>0.697917</td>\n",
              "      <td>0.737821</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>27</td>\n",
              "      <td>Chunky</td>\n",
              "      <td>game show</td>\n",
              "      <td>0.690265</td>\n",
              "      <td>0.762241</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83</th>\n",
              "      <td>84</td>\n",
              "      <td>Photo Wall of Metal: Metal Motto Search</td>\n",
              "      <td>game show</td>\n",
              "      <td>0.684211</td>\n",
              "      <td>0.788549</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    sketch_id                              sketch_name    category  \\\n",
              "64         65              Supermarket Swap VR Edition   game show   \n",
              "77         78                      Summer Loving Pt. 2      dating   \n",
              "1           2            Has This Ever Happened To You  commercial   \n",
              "23         24       The Day Robert Palin's Murdered Me       music   \n",
              "32         33                              Coffin Flop  commercial   \n",
              "56         57                              Tammy Craps  commercial   \n",
              "31         32                            Lunch Meeting      office   \n",
              "48         49                         Calico Cut Pants      office   \n",
              "26         27                                   Chunky   game show   \n",
              "83         84  Photo Wall of Metal: Metal Motto Search   game show   \n",
              "\n",
              "    pct_neutral  avg_score  \n",
              "64     0.810127   0.762706  \n",
              "77     0.750000   0.903059  \n",
              "1      0.727273   0.750548  \n",
              "23     0.724638   0.801930  \n",
              "32     0.722222   0.759734  \n",
              "56     0.714286   0.791690  \n",
              "31     0.711111   0.697896  \n",
              "48     0.697917   0.737821  \n",
              "26     0.690265   0.762241  \n",
              "83     0.684211   0.788549  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 6. Most emotional vs. most neutral sketches\n",
        "sketch_stats = df.groupby('sketch_id').agg({\n",
        "    'sentiment_label': lambda x: (x == 'neutral').sum() / len(x),  # % neutral\n",
        "    'sentiment_score': ['mean', 'std'],\n",
        "    'sentence_index': 'count'  # sketch length\n",
        "}).reset_index()\n",
        "sketch_stats.columns = ['sketch_id', 'pct_neutral', 'avg_score', 'score_std', 'length']\n",
        "\n",
        "# Add sketch names and category\n",
        "sketch_stats = sketch_stats.merge(\n",
        "    df[['sketch_id', 'sketch_name']].drop_duplicates(),\n",
        "    on='sketch_id'\n",
        ")\n",
        "if 'category' in df_merged.columns:\n",
        "    sketch_stats = sketch_stats.merge(\n",
        "        df_merged[['sketch_id', 'category']].drop_duplicates(),\n",
        "        on='sketch_id',\n",
        "        how='left'\n",
        "    )\n",
        "\n",
        "# Show 10 sketches with lowest % neutral (most emotional)\n",
        "most_emotional = sketch_stats.nsmallest(10, 'pct_neutral')[['sketch_id', 'sketch_name', 'category', 'pct_neutral', 'avg_score']]\n",
        "print(\"Most emotional sketches (top 10) as DataFrame:\")\n",
        "display(most_emotional)\n",
        "\n",
        "# Show 10 sketches with highest % neutral (most neutral)\n",
        "most_neutral = sketch_stats.nlargest(10, 'pct_neutral')[['sketch_id', 'sketch_name', 'category', 'pct_neutral', 'avg_score']]\n",
        "print(\"Most neutral sketches (top 10) as DataFrame:\")\n",
        "display(most_neutral)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "48b75a12",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Emotion counts: for sketch 43 (Detective Crashmore Trailer)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "sentiment_label\n",
              "neutral        16\n",
              "anger          10\n",
              "annoyance       4\n",
              "excitement      3\n",
              "disapproval     2\n",
              "sadness         1\n",
              "remorse         1\n",
              "caring          1\n",
              "love            1\n",
              "admiration      1\n",
              "approval        1\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# examining emotion counts for individual sketches\n",
        "sk_id = 43\n",
        "emotion_counts = df[df['sketch_id'] == sk_id]['sentiment_label'].value_counts()\n",
        "sketch_name = df.loc[df['sketch_id'] == sk_id, 'sketch_name'].iloc[0]\n",
        "print(f\"Emotion counts: for sketch {sk_id} ({sketch_name})\")\n",
        "emotion_counts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "5787080b",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sketch_id</th>\n",
              "      <th>sentence_text</th>\n",
              "      <th>sentiment_label</th>\n",
              "      <th>sentiment_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1612</th>\n",
              "      <td>25</td>\n",
              "      <td>It's not a problem!</td>\n",
              "      <td>approval</td>\n",
              "      <td>0.688210</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1499</th>\n",
              "      <td>24</td>\n",
              "      <td>The don't want to hear songs they can hear in ...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.738013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3135</th>\n",
              "      <td>47</td>\n",
              "      <td>I should quit I don't even know what I'm doing.</td>\n",
              "      <td>confusion</td>\n",
              "      <td>0.734979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4646</th>\n",
              "      <td>65</td>\n",
              "      <td>Get him out of there!</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.676165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4915</th>\n",
              "      <td>69</td>\n",
              "      <td>I did.</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.586206</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      sketch_id                                      sentence_text  \\\n",
              "1612         25                                It's not a problem!   \n",
              "1499         24  The don't want to hear songs they can hear in ...   \n",
              "3135         47    I should quit I don't even know what I'm doing.   \n",
              "4646         65                              Get him out of there!   \n",
              "4915         69                                             I did.   \n",
              "\n",
              "     sentiment_label  sentiment_score  \n",
              "1612        approval         0.688210  \n",
              "1499         neutral         0.738013  \n",
              "3135       confusion         0.734979  \n",
              "4646         neutral         0.676165  \n",
              "4915         neutral         0.586206  "
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "# show 5 random sentences\n",
        "sample_rows = df.sample(5)\n",
        "sample_display_multi = sample_rows[['sketch_id', 'sentence_text', 'sentiment_label', 'sentiment_score']]\n",
        "sample_display_multi\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cff8fca4",
      "metadata": {},
      "source": [
        "## Heatmap: Emotions Over Time for Each Sketch\n",
        "\n",
        "Prepare data for a heatmap showing emotion evolution across all 86 sketches.\n",
        "- Y-axis: Sketches (ordered by season, episode, sketch_id)\n",
        "- X-axis: Time (normalized position within sketch, binned)\n",
        "- Color: Emotion type\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7744f8cc",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare data for sketch × time heatmap\n",
        "# Normalize time position for each sketch (0-100)\n",
        "df['time_percent'] = df['relative_position'] * 100\n",
        "\n",
        "# Create time bins (e.g., 0-5%, 5-10%, etc.)\n",
        "# Using 20 bins (5% increments) for good resolution without too much granularity\n",
        "NUM_TIME_BINS = 20\n",
        "df['time_bin'] = pd.cut(df['time_percent'], \n",
        "                        bins=NUM_TIME_BINS, \n",
        "                        labels=[f\"{i*100/NUM_TIME_BINS:.1f}-{(i+1)*100/NUM_TIME_BINS:.1f}%\" \n",
        "                                for i in range(NUM_TIME_BINS)],\n",
        "                        include_lowest=True)\n",
        "\n",
        "# Get sketch metadata for ordering\n",
        "sketch_order = df[['sketch_id', 'sketch_name', 'season', 'episode']].drop_duplicates().sort_values(\n",
        "    ['season', 'episode', 'sketch_id']\n",
        ").reset_index(drop=True)\n",
        "sketch_order['sketch_order'] = sketch_order.index\n",
        "\n",
        "# Add ordering to main dataframe\n",
        "df = df.merge(sketch_order[['sketch_id', 'sketch_order']], on='sketch_id')\n",
        "\n",
        "print(f\"Time bins: {NUM_TIME_BINS} bins ({100/NUM_TIME_BINS:.1f}% each)\")\n",
        "print(f\"Total sketches: {len(sketch_order)}\")\n",
        "print(f\"\\nFirst few sketches in order:\")\n",
        "print(sketch_order.head(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54aec44c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# For each sketch × time_bin, capture ALL emotions (not just dominant)\n",
        "# This allows visualization of the full range of emotions\n",
        "heatmap_data_all = df.groupby(['sketch_id', 'time_bin', 'sentiment_label'], observed=True).size().reset_index(name='count')\n",
        "\n",
        "# Calculate total sentences per bin for percentages\n",
        "bin_totals = df.groupby(['sketch_id', 'time_bin'], observed=True).size().reset_index(name='total_sentences')\n",
        "heatmap_data_all = heatmap_data_all.merge(bin_totals, on=['sketch_id', 'time_bin'])\n",
        "heatmap_data_all['percentage'] = (heatmap_data_all['count'] / heatmap_data_all['total_sentences']) * 100\n",
        "\n",
        "# Also determine the dominant emotion for comparison\n",
        "heatmap_data_sorted = heatmap_data_all.sort_values(['sketch_id', 'time_bin', 'count'], ascending=[True, True, False])\n",
        "dominant_emotions = heatmap_data_sorted.groupby(['sketch_id', 'time_bin'], observed=True).first().reset_index()\n",
        "dominant_emotions = dominant_emotions[['sketch_id', 'time_bin', 'sentiment_label', 'count', 'total_sentences']]\n",
        "dominant_emotions['dominance_ratio'] = dominant_emotions['count'] / dominant_emotions['total_sentences']\n",
        "\n",
        "print(\"Sample of ALL emotions by sketch × time bin (showing range):\")\n",
        "print(heatmap_data_all.head(20))\n",
        "print(f\"\\nTotal emotion × time_bin combinations: {len(heatmap_data_all)}\")\n",
        "print(f\"Average emotions per sketch × time_bin: {heatmap_data_all.groupby(['sketch_id', 'time_bin'], observed=True).size().mean():.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "955d9961",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Add sketch metadata and ordering to ALL emotions dataset\n",
        "heatmap_all_emotions = heatmap_data_all.merge(\n",
        "    sketch_order[['sketch_id', 'sketch_name', 'season', 'episode', 'sketch_order']],\n",
        "    on='sketch_id'\n",
        ")\n",
        "\n",
        "# Add category if available\n",
        "if 'category' in df_merged.columns:\n",
        "    sketch_categories = df_merged[['sketch_id', 'category', 'category2']].drop_duplicates()\n",
        "    heatmap_all_emotions = heatmap_all_emotions.merge(sketch_categories, on='sketch_id', how='left')\n",
        "\n",
        "# Convert time_bin to numeric for easier sorting/plotting\n",
        "heatmap_all_emotions['time_bin_start'] = heatmap_all_emotions['time_bin'].astype(str).str.split('-').str[0].str.rstrip('%').astype(float)\n",
        "heatmap_all_emotions['time_bin_end'] = heatmap_all_emotions['time_bin'].astype(str).str.split('-').str[1].str.rstrip('%').astype(float)\n",
        "heatmap_all_emotions['time_bin_center'] = (heatmap_all_emotions['time_bin_start'] + heatmap_all_emotions['time_bin_end']) / 2\n",
        "\n",
        "# Sort by sketch order, time bin, and count (descending)\n",
        "heatmap_all_emotions = heatmap_all_emotions.sort_values(['sketch_order', 'time_bin_start', 'count'], ascending=[True, True, False]).reset_index(drop=True)\n",
        "\n",
        "# Also create dominant-only version for comparison\n",
        "heatmap_export = dominant_emotions.merge(\n",
        "    sketch_order[['sketch_id', 'sketch_name', 'season', 'episode', 'sketch_order']],\n",
        "    on='sketch_id'\n",
        ")\n",
        "if 'category' in df_merged.columns:\n",
        "    heatmap_export = heatmap_export.merge(sketch_categories, on='sketch_id', how='left')\n",
        "heatmap_export['time_bin_start'] = heatmap_export['time_bin'].astype(str).str.split('-').str[0].str.rstrip('%').astype(float)\n",
        "heatmap_export['time_bin_end'] = heatmap_export['time_bin'].astype(str).str.split('-').str[1].str.rstrip('%').astype(float)\n",
        "heatmap_export['time_bin_center'] = (heatmap_export['time_bin_start'] + heatmap_export['time_bin_end']) / 2\n",
        "heatmap_export = heatmap_export.sort_values(['sketch_order', 'time_bin_start']).reset_index(drop=True)\n",
        "\n",
        "print(f\"ALL emotions heatmap data shape: {heatmap_all_emotions.shape}\")\n",
        "print(f\"Dominant-only heatmap data shape: {heatmap_export.shape}\")\n",
        "print(f\"\\nSample of ALL emotions data (shows range):\")\n",
        "print(heatmap_all_emotions[['sketch_name', 'time_bin', 'sentiment_label', 'count', 'percentage']].head(20))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "352590e7",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Also create an alternative version with average sentiment score per bin\n",
        "# This could be useful for a continuous color scale\n",
        "heatmap_score_data = df.groupby(['sketch_id', 'time_bin'], observed=True).agg({\n",
        "    'sentiment_score': 'mean',\n",
        "    'sentiment_label': lambda x: x.mode()[0] if len(x.mode()) > 0 else 'neutral'  # most common emotion\n",
        "}).reset_index()\n",
        "heatmap_score_data.columns = ['sketch_id', 'time_bin', 'avg_sentiment_score', 'most_common_emotion']\n",
        "\n",
        "# Add metadata\n",
        "heatmap_score_export = heatmap_score_data.merge(\n",
        "    sketch_order[['sketch_id', 'sketch_name', 'season', 'episode', 'sketch_order']],\n",
        "    on='sketch_id'\n",
        ")\n",
        "if 'category' in df_merged.columns:\n",
        "    heatmap_score_export = heatmap_score_export.merge(sketch_categories, on='sketch_id', how='left')\n",
        "\n",
        "# Add time bin numeric values\n",
        "heatmap_score_export['time_bin_start'] = heatmap_score_export['time_bin'].astype(str).str.split('-').str[0].str.rstrip('%').astype(float)\n",
        "heatmap_score_export['time_bin_end'] = heatmap_score_export['time_bin'].astype(str).str.split('-').str[1].str.rstrip('%').astype(float)\n",
        "heatmap_score_export['time_bin_center'] = (heatmap_score_export['time_bin_start'] + heatmap_score_export['time_bin_end']) / 2\n",
        "\n",
        "heatmap_score_export = heatmap_score_export.sort_values(['sketch_order', 'time_bin_start']).reset_index(drop=True)\n",
        "\n",
        "print(\"Alternative version with sentiment scores:\")\n",
        "print(heatmap_score_export[['sketch_name', 'time_bin', 'most_common_emotion', 'avg_sentiment_score']].head(15))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ba477d8",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create comprehensive exports with multiple versions\n",
        "# Version 1: ALL emotions per time bin (shows full range)\n",
        "heatmap_all_final = heatmap_all_emotions[[\n",
        "    'sketch_id', 'sketch_name', 'sketch_order', 'season', 'episode',\n",
        "    'time_bin', 'time_bin_start', 'time_bin_end', 'time_bin_center',\n",
        "    'sentiment_label', 'count', 'total_sentences', 'percentage'\n",
        "]]\n",
        "\n",
        "if 'category' in heatmap_all_emotions.columns:\n",
        "    heatmap_all_final['category'] = heatmap_all_emotions['category']\n",
        "    if 'category2' in heatmap_all_emotions.columns:\n",
        "        heatmap_all_final['category2'] = heatmap_all_emotions['category2']\n",
        "\n",
        "# Version 2: Dominant emotion only (simpler heatmap)\n",
        "heatmap_final = heatmap_export[[\n",
        "    'sketch_id', 'sketch_name', 'sketch_order', 'season', 'episode',\n",
        "    'time_bin', 'time_bin_start', 'time_bin_end', 'time_bin_center',\n",
        "    'sentiment_label', 'count', 'total_sentences', 'dominance_ratio'\n",
        "]]\n",
        "\n",
        "if 'category' in heatmap_export.columns:\n",
        "    heatmap_final['category'] = heatmap_export['category']\n",
        "    if 'category2' in heatmap_export.columns:\n",
        "        heatmap_final['category2'] = heatmap_export['category2']\n",
        "\n",
        "# Version 3: Score-based version\n",
        "heatmap_score_final = heatmap_score_export[[\n",
        "    'sketch_id', 'sketch_name', 'sketch_order', 'season', 'episode',\n",
        "    'time_bin', 'time_bin_start', 'time_bin_end', 'time_bin_center',\n",
        "    'most_common_emotion', 'avg_sentiment_score'\n",
        "]]\n",
        "\n",
        "if 'category' in heatmap_score_export.columns:\n",
        "    heatmap_score_final['category'] = heatmap_score_export['category']\n",
        "    if 'category2' in heatmap_score_export.columns:\n",
        "        heatmap_score_final['category2'] = heatmap_score_export['category2']\n",
        "\n",
        "# Calculate emotion diversity metrics per sketch\n",
        "emotion_diversity = heatmap_all_emotions.groupby('sketch_id').agg({\n",
        "    'sentiment_label': 'nunique',  # number of unique emotions\n",
        "    'count': 'sum'  # total sentences\n",
        "}).reset_index()\n",
        "emotion_diversity.columns = ['sketch_id', 'num_unique_emotions', 'total_sentences']\n",
        "emotion_diversity = emotion_diversity.merge(\n",
        "    sketch_order[['sketch_id', 'sketch_name', 'season', 'episode', 'sketch_order']],\n",
        "    on='sketch_id'\n",
        ")\n",
        "\n",
        "print(\"Final heatmap datasets prepared:\")\n",
        "print(f\"  - ALL emotions version (shows range): {len(heatmap_all_final)} rows\")\n",
        "print(f\"  - Dominant emotion version: {len(heatmap_final)} rows\")\n",
        "print(f\"  - Score-based version: {len(heatmap_score_final)} rows\")\n",
        "print(f\"\\nUnique emotions across all sketches: {heatmap_all_final['sentiment_label'].nunique()}\")\n",
        "print(f\"Emotions: {sorted(heatmap_all_final['sentiment_label'].unique())}\")\n",
        "print(f\"\\nEmotion diversity per sketch:\")\n",
        "print(f\"  Average unique emotions per sketch: {emotion_diversity['num_unique_emotions'].mean():.2f}\")\n",
        "print(f\"  Range: {emotion_diversity['num_unique_emotions'].min()} - {emotion_diversity['num_unique_emotions'].max()} unique emotions\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f252568",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Update the export JSON to include heatmap data\n",
        "# Read existing export if it exists, otherwise create new structure\n",
        "try:\n",
        "    with open('sentiment_analysis_export.json', 'r') as f:\n",
        "        export_data = json.load(f)\n",
        "except FileNotFoundError:\n",
        "    export_data = {}\n",
        "\n",
        "# Add heatmap data - ALL versions\n",
        "export_data['sketch_heatmap_all'] = heatmap_all_final.to_dict('records')  # ALL emotions (shows range)\n",
        "export_data['sketch_heatmap'] = heatmap_final.to_dict('records')  # Dominant only\n",
        "export_data['sketch_heatmap_scores'] = heatmap_score_final.to_dict('records')  # Score-based\n",
        "export_data['emotion_diversity'] = emotion_diversity.to_dict('records')  # Diversity metrics per sketch\n",
        "\n",
        "# Add metadata about the heatmap\n",
        "export_data['heatmap_metadata'] = {\n",
        "    'num_time_bins': NUM_TIME_BINS,\n",
        "    'bin_size_percent': 100 / NUM_TIME_BINS,\n",
        "    'num_sketches': len(sketch_order),\n",
        "    'sketch_order': sketch_order[['sketch_id', 'sketch_name', 'season', 'episode', 'sketch_order']].to_dict('records'),\n",
        "    'unique_emotions': sorted(heatmap_all_final['sentiment_label'].unique().tolist()),\n",
        "    'avg_emotions_per_bin': heatmap_all_emotions.groupby(['sketch_id', 'time_bin'], observed=True).size().mean()\n",
        "}\n",
        "\n",
        "# Save updated export\n",
        "with open('sentiment_analysis_export.json', 'w') as f:\n",
        "    json.dump(export_data, f, indent=2)\n",
        "\n",
        "print(\"Heatmap data added to sentiment_analysis_export.json\")\n",
        "print(f\"\\nHeatmap structure:\")\n",
        "print(f\"  - sketch_heatmap_all: ALL emotions per sketch × time bin (shows full range)\")\n",
        "print(f\"  - sketch_heatmap: Dominant emotion per sketch × time bin (simpler)\")\n",
        "print(f\"  - sketch_heatmap_scores: Average sentiment score per sketch × time bin\")\n",
        "print(f\"  - emotion_diversity: Emotion diversity metrics per sketch\")\n",
        "print(f\"  - heatmap_metadata: Configuration and reference data\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17c5bca2",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Preview: Show samples of both data structures\n",
        "print(\"=\" * 80)\n",
        "print(\"SAMPLE 1: Dominant emotion only (simpler heatmap)\")\n",
        "print(\"=\" * 80)\n",
        "sample_sketch_dominant = heatmap_final[heatmap_final['sketch_order'] == 0].head(5)\n",
        "print(sample_sketch_dominant[['sketch_name', 'time_bin', 'sentiment_label', 'dominance_ratio']].to_string(index=False))\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"SAMPLE 2: ALL emotions (shows full range - multiple rows per time bin)\")\n",
        "print(\"=\" * 80)\n",
        "sample_sketch_all = heatmap_all_final[heatmap_all_final['sketch_order'] == 0].head(10)\n",
        "print(sample_sketch_all[['sketch_name', 'time_bin', 'sentiment_label', 'count', 'percentage']].to_string(index=False))\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"DATA STRUCTURE FOR OBSERVABLE PLOT\")\n",
        "print(\"=\" * 80)\n",
        "print(\"\\nFor visualizing RANGE of emotions, use 'sketch_heatmap_all':\")\n",
        "print(\"  - Multiple records per sketch × time_bin (one per emotion present)\")\n",
        "print(\"  - Each record contains:\")\n",
        "print(\"    - sketch_id, sketch_name, sketch_order (for Y-axis ordering)\")\n",
        "print(\"    - season, episode (for grouping/filtering)\")\n",
        "print(\"    - time_bin, time_bin_start, time_bin_end, time_bin_center (for X-axis)\")\n",
        "print(\"    - sentiment_label (for color mapping)\")\n",
        "print(\"    - count, percentage (how many sentences, what % of bin)\")\n",
        "print(\"    - category, category2 (if available, for filtering/grouping)\")\n",
        "print(\"\\nFor simpler dominant-only heatmap, use 'sketch_heatmap':\")\n",
        "print(\"  - One record per sketch × time_bin (dominant emotion only)\")\n",
        "print(\"  - Same fields as above, plus 'dominance_ratio'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8393628",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "852e8f04",
      "metadata": {},
      "source": [
        "## Data Structure: Emotions in Order of Appearance per Sketch\n",
        "\n",
        "Create a structured data format that organizes emotions chronologically for each sketch, making it easy to visualize the emotional arc over time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae2c750c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ensure data is sorted by sketch_id and sentence_index for chronological order\n",
        "# Use df_merged if it exists, otherwise use df (which has season/episode from CSV)\n",
        "if 'df_merged' in globals() and df_merged is not None:\n",
        "    df_sorted = df_merged.sort_values(['sketch_id', 'sentence_index']).reset_index(drop=True)\n",
        "else:\n",
        "    # Merge with metadata if df_merged doesn't exist\n",
        "    if 'metadata' not in globals():\n",
        "        metadata = pd.read_csv('episode_metadata.csv')\n",
        "    df_sorted = df.merge(metadata, left_on='sketch_id', right_on='id', how='left')\n",
        "    df_sorted = df_sorted.sort_values(['sketch_id', 'sentence_index']).reset_index(drop=True)\n",
        "\n",
        "# Get all unique emotions for reference\n",
        "all_emotions = sorted(df_sorted['sentiment_label'].unique())\n",
        "print(f\"Total unique emotions: {len(all_emotions)}\")\n",
        "print(f\"All emotions: {all_emotions}\")\n",
        "print(f\"\\nColumns in df_sorted: {list(df_sorted.columns)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df180cf9",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create the main data structure: emotions in order of appearance per sketch\n",
        "emotions_by_sketch = {}\n",
        "\n",
        "# Process each sketch\n",
        "for sketch_id in sorted(df_sorted['sketch_id'].unique()):\n",
        "    sketch_data = df_sorted[df_sorted['sketch_id'] == sketch_id].copy()\n",
        "    \n",
        "    # Get sketch metadata (should be same for all rows of a sketch)\n",
        "    first_row = sketch_data.iloc[0]\n",
        "    \n",
        "    # Create ordered list of emotions with their positions\n",
        "    emotion_sequence = []\n",
        "    for idx, row in sketch_data.iterrows():\n",
        "        emotion_sequence.append({\n",
        "            'position': int(row['sentence_index']),\n",
        "            'emotion': row['sentiment_label'],\n",
        "            'confidence': float(row['sentiment_score']),\n",
        "            'sentence_text': row['sentence_text']\n",
        "        })\n",
        "    \n",
        "    # Store in dictionary (use .get() for columns that might not exist)\n",
        "    emotions_by_sketch[sketch_id] = {\n",
        "        'sketch_id': int(sketch_id),\n",
        "        'sketch_name': first_row.get('sketch_name', ''),\n",
        "        'season': int(first_row.get('season', 0)),\n",
        "        'episode': int(first_row.get('episode', 0)),\n",
        "        'category': first_row.get('category', ''),\n",
        "        'category2': first_row.get('category2', ''),\n",
        "        'start_time': first_row.get('start', ''),\n",
        "        'end_time': first_row.get('end', ''),\n",
        "        'total_sentences': len(emotion_sequence),\n",
        "        'emotion_sequence': emotion_sequence,  # Ordered list of emotions\n",
        "        'emotion_counts': sketch_data['sentiment_label'].value_counts().to_dict(),  # Count of each emotion\n",
        "        'unique_emotions': sorted(sketch_data['sentiment_label'].unique().tolist())  # Unique emotions in this sketch\n",
        "    }\n",
        "\n",
        "print(f\"Created data structure for {len(emotions_by_sketch)} sketches\")\n",
        "# Get first available sketch ID for example\n",
        "first_sketch_id = min(emotions_by_sketch.keys()) if emotions_by_sketch else None\n",
        "if first_sketch_id:\n",
        "    print(f\"\\nExample structure for sketch {first_sketch_id}:\")\n",
        "    example_keys = ['sketch_id', 'sketch_name', 'season', 'episode', 'category', 'total_sentences', 'unique_emotions']\n",
        "    example_dict = {k: emotions_by_sketch[first_sketch_id][k] for k in example_keys}\n",
        "    print(json.dumps(example_dict, indent=2))\n",
        "    print(f\"\\nFirst 5 emotions in sequence:\")\n",
        "    for i, emo in enumerate(emotions_by_sketch[first_sketch_id]['emotion_sequence'][:5]):\n",
        "        print(f\"  {i+1}. Position {emo['position']}: {emo['emotion']} (confidence: {emo['confidence']:.3f})\")\n",
        "else:\n",
        "    print(\"No sketches found in data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a419e04f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a normalized position-based structure for easier charting\n",
        "# This converts sentence positions to normalized positions (0.0 to 1.0) within each sketch\n",
        "\n",
        "emotions_by_sketch_normalized = {}\n",
        "\n",
        "for sketch_id, data in emotions_by_sketch.items():\n",
        "    emotion_sequence_normalized = []\n",
        "    total = data['total_sentences']\n",
        "    \n",
        "    for emo in data['emotion_sequence']:\n",
        "        normalized_position = (emo['position'] - 1) / max(total - 1, 1)  # 0.0 to 1.0\n",
        "        emotion_sequence_normalized.append({\n",
        "            'normalized_position': float(normalized_position),\n",
        "            'position': emo['position'],\n",
        "            'emotion': emo['emotion'],\n",
        "            'confidence': emo['confidence']\n",
        "        })\n",
        "    \n",
        "    emotions_by_sketch_normalized[sketch_id] = {\n",
        "        **{k: v for k, v in data.items() if k != 'emotion_sequence'},\n",
        "        'emotion_sequence_normalized': emotion_sequence_normalized\n",
        "    }\n",
        "\n",
        "print(f\"Created normalized position structure for {len(emotions_by_sketch_normalized)} sketches\")\n",
        "# Get first available sketch ID for example\n",
        "first_sketch_id = min(emotions_by_sketch_normalized.keys()) if emotions_by_sketch_normalized else None\n",
        "if first_sketch_id:\n",
        "    print(f\"\\nExample normalized sequence for sketch {first_sketch_id} (first 5):\")\n",
        "    for emo in emotions_by_sketch_normalized[first_sketch_id]['emotion_sequence_normalized'][:5]:\n",
        "        print(f\"  Position {emo['normalized_position']:.3f} (sentence {emo['position']}): {emo['emotion']}\")\n",
        "else:\n",
        "    print(\"No sketches found in normalized data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "397442bc",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a long-format DataFrame for easier plotting\n",
        "# Each row represents one emotion occurrence at a specific position in a sketch\n",
        "\n",
        "plotting_data = []\n",
        "\n",
        "for sketch_id, data in emotions_by_sketch.items():\n",
        "    for emo in data['emotion_sequence']:\n",
        "        plotting_data.append({\n",
        "            'sketch_id': data['sketch_id'],\n",
        "            'sketch_name': data['sketch_name'],\n",
        "            'season': data['season'],\n",
        "            'episode': data['episode'],\n",
        "            'category': data['category'],\n",
        "            'category2': data['category2'],\n",
        "            'position': emo['position'],\n",
        "            'normalized_position': (emo['position'] - 1) / max(data['total_sentences'] - 1, 1),\n",
        "            'emotion': emo['emotion'],\n",
        "            'confidence': emo['confidence']\n",
        "        })\n",
        "\n",
        "df_emotions_plotting = pd.DataFrame(plotting_data)\n",
        "\n",
        "print(f\"Plotting DataFrame shape: {df_emotions_plotting.shape}\")\n",
        "print(f\"\\nFirst 10 rows:\")\n",
        "df_emotions_plotting.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1199842",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a summary DataFrame for easier analysis\n",
        "sketch_summaries = []\n",
        "\n",
        "for sketch_id, data in emotions_by_sketch.items():\n",
        "    # Create a simple list of emotions in order\n",
        "    emotion_list = [e['emotion'] for e in data['emotion_sequence']]\n",
        "    \n",
        "    sketch_summaries.append({\n",
        "        'sketch_id': data['sketch_id'],\n",
        "        'sketch_name': data['sketch_name'],\n",
        "        'season': data['season'],\n",
        "        'episode': data['episode'],\n",
        "        'category': data['category'],\n",
        "        'category2': data['category2'],\n",
        "        'total_sentences': data['total_sentences'],\n",
        "        'num_unique_emotions': len(data['unique_emotions']),\n",
        "        'emotion_sequence': emotion_list,  # List of emotions in order\n",
        "        'emotion_string': ' -> '.join(emotion_list),  # String representation for quick viewing\n",
        "        'emotion_counts': data['emotion_counts']\n",
        "    })\n",
        "\n",
        "df_sketch_emotions_summary = pd.DataFrame(sketch_summaries)\n",
        "\n",
        "print(f\"Summary DataFrame shape: {df_sketch_emotions_summary.shape}\")\n",
        "print(f\"\\nFirst few sketches:\")\n",
        "df_sketch_emotions_summary[['sketch_id', 'sketch_name', 'season', 'episode', 'total_sentences', 'num_unique_emotions', 'emotion_string']].head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec2601ca",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display statistics about the data structure\n",
        "print(\"=\" * 60)\n",
        "print(\"DATA STRUCTURE STATISTICS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(f\"\\nTotal sketches: {len(emotions_by_sketch)}\")\n",
        "print(f\"Total emotion occurrences: {len(df_emotions_plotting)}\")\n",
        "print(f\"Total unique emotions: {len(all_emotions)}\")\n",
        "print(f\"\\nAll {len(all_emotions)} emotions:\")\n",
        "for i, emo in enumerate(all_emotions, 1):\n",
        "    print(f\"  {i:2d}. {emo}\")\n",
        "\n",
        "print(f\"\\n\\nSketches by season:\")\n",
        "print(df_emotions_plotting.groupby('season')['sketch_id'].nunique())\n",
        "\n",
        "print(f\"\\n\\nSketches by episode:\")\n",
        "episode_counts = df_emotions_plotting.groupby(['season', 'episode'])['sketch_id'].nunique()\n",
        "print(episode_counts)\n",
        "\n",
        "print(f\"\\n\\nAverage emotions per sketch:\")\n",
        "emotions_per_sketch = df_emotions_plotting.groupby('sketch_id').size()\n",
        "print(f\"  Mean: {emotions_per_sketch.mean():.1f}\")\n",
        "print(f\"  Median: {emotions_per_sketch.median():.1f}\")\n",
        "print(f\"  Min: {emotions_per_sketch.min()}\")\n",
        "print(f\"  Max: {emotions_per_sketch.max()}\")\n",
        "\n",
        "print(f\"\\n\\nEmotion distribution across all sketches:\")\n",
        "emotion_counts = df_emotions_plotting['emotion'].value_counts()\n",
        "print(emotion_counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1e78bfc",
      "metadata": {},
      "source": [
        "### Data Structure Summary\n",
        "\n",
        "**Main Data Structures Created:**\n",
        "\n",
        "1. **`emotions_by_sketch`** (dict): \n",
        "   - Key: sketch_id\n",
        "   - Value: Dictionary containing:\n",
        "     - Sketch metadata (id, name, season, episode, category, etc.)\n",
        "     - `emotion_sequence`: List of emotions in order of appearance with position, confidence, and sentence text\n",
        "     - `emotion_counts`: Count of each emotion type\n",
        "     - `unique_emotions`: List of unique emotions in the sketch\n",
        "\n",
        "2. **`emotions_by_sketch_normalized`** (dict):\n",
        "   - Same as above but with normalized positions (0.0 to 1.0) for easier comparison across sketches of different lengths\n",
        "\n",
        "3. **`df_emotions_plotting`** (DataFrame):\n",
        "   - Long-format DataFrame with one row per emotion occurrence\n",
        "   - Columns: sketch_id, sketch_name, season, episode, category, position, normalized_position, emotion, confidence\n",
        "   - Ideal for creating charts with libraries like matplotlib, plotly, or seaborn\n",
        "\n",
        "4. **`df_sketch_emotions_summary`** (DataFrame):\n",
        "   - Summary DataFrame with one row per sketch\n",
        "   - Includes emotion_sequence as a list and emotion_string for quick viewing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "356e19ed",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data structures saved:\n",
            "  ✓ emotions_by_sketch_structured.json: Full structured data\n",
            "  ✓ emotions_by_sketch_normalized.json: Normalized position data\n",
            "  ✓ emotions_plotting_data.csv: Long-format DataFrame for plotting\n",
            "  ✓ emotions_by_sketch_summary.csv: Summary DataFrame\n"
          ]
        }
      ],
      "source": [
        "# Save the data structures for later use\n",
        "# Helper function to convert numpy types to native Python types for JSON serialization\n",
        "def convert_to_json_serializable(obj):\n",
        "    \"\"\"Recursively convert numpy types to native Python types\"\"\"\n",
        "    import numpy as np\n",
        "    if isinstance(obj, dict):\n",
        "        # Convert keys: numpy int64 -> regular Python int (JSON accepts int keys)\n",
        "        result = {}\n",
        "        for k, v in obj.items():\n",
        "            # Convert numpy int64/int32 to regular Python int\n",
        "            if isinstance(k, (np.integer, np.int64, np.int32)):\n",
        "                key = int(k)\n",
        "            else:\n",
        "                key = k\n",
        "            result[key] = convert_to_json_serializable(v)\n",
        "        return result\n",
        "    elif isinstance(obj, list):\n",
        "        return [convert_to_json_serializable(item) for item in obj]\n",
        "    elif isinstance(obj, (np.integer, np.int64, np.int32)):\n",
        "        return int(obj)\n",
        "    elif isinstance(obj, (np.floating, np.float64, np.float32)):\n",
        "        return float(obj)\n",
        "    elif isinstance(obj, np.ndarray):\n",
        "        return obj.tolist()\n",
        "    else:\n",
        "        return obj\n",
        "\n",
        "# 1. Full structured data (JSON)\n",
        "emotions_by_sketch_json = convert_to_json_serializable(emotions_by_sketch)\n",
        "with open('emotions_by_sketch_structured.json', 'w') as f:\n",
        "    json.dump(emotions_by_sketch_json, f, indent=2)\n",
        "\n",
        "# 2. Normalized version (JSON)\n",
        "emotions_by_sketch_normalized_json = convert_to_json_serializable(emotions_by_sketch_normalized)\n",
        "with open('emotions_by_sketch_normalized.json', 'w') as f:\n",
        "    json.dump(emotions_by_sketch_normalized_json, f, indent=2)\n",
        "\n",
        "# 3. Plotting DataFrame (CSV)\n",
        "df_emotions_plotting.to_csv('emotions_plotting_data.csv', index=False)\n",
        "\n",
        "# 4. Summary DataFrame (CSV) - note: emotion_sequence column will be saved as string representation\n",
        "df_sketch_emotions_export = df_sketch_emotions_summary.copy()\n",
        "df_sketch_emotions_export['emotion_sequence'] = df_sketch_emotions_export['emotion_sequence'].apply(lambda x: '|'.join(x))\n",
        "df_sketch_emotions_export.to_csv('emotions_by_sketch_summary.csv', index=False)\n",
        "\n",
        "print(\"Data structures saved:\")\n",
        "print(\"  ✓ emotions_by_sketch_structured.json: Full structured data\")\n",
        "print(\"  ✓ emotions_by_sketch_normalized.json: Normalized position data\")\n",
        "print(\"  ✓ emotions_plotting_data.csv: Long-format DataFrame for plotting\")\n",
        "print(\"  ✓ emotions_by_sketch_summary.csv: Summary DataFrame\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cddc6db5",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv (3.13.5)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
