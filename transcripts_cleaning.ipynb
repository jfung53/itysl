{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ebca80a",
   "metadata": {},
   "source": [
    "### Cleanup of scraped transcripts for sentiment analysis\n",
    "\n",
    "The [transcripts that I found](https://itysldb.com/) were continuous blocks of dialogue text, not scripts. Somewhere along the line, some numbers and words were lost or just not accounted for.  I did a manual scan while watching each episode again to fill in some of the blanks, but there are probably still some errors that I missed. \n",
    "\n",
    "This notebook uses the NLP library `spaCy` to identify and extract full sentences.  I'll then conduct [sentiment analysis](https://colab.research.google.com/drive/1GuUbnw1pVMQrNDVKJ98bJGYvR3YWWB_D?usp=sharing) on the individual sentences.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd1089f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy # for nlp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62f3e473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transcripts scraped from https://itysldb.com/\n",
    "df = pd.read_json('transcripts.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71a3bfcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slug</th>\n",
       "      <th>name</th>\n",
       "      <th>season</th>\n",
       "      <th>episode</th>\n",
       "      <th>id</th>\n",
       "      <th>netflixLink</th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>both-ways</td>\n",
       "      <td>Both Ways</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.netflix.com/watch/80986856?t=7</td>\n",
       "      <td>Obviously, I'd love to work for you, and I app...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>has-this-ever-happened-to-you</td>\n",
       "      <td>Has This Ever Happened To You</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>https://www.netflix.com/watch/80986856?t=101</td>\n",
       "      <td>Have you been the victim of unfair treatment b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>baby-of-the-year</td>\n",
       "      <td>Baby of the Year</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>https://www.netflix.com/watch/80986856?t=208</td>\n",
       "      <td>Look at their rolls. Look at their folds. Look...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>instagram</td>\n",
       "      <td>Instagram</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>https://www.netflix.com/watch/80986856?t=444</td>\n",
       "      <td>Let me see it. Oh yeah that's good. That's gre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gift-receipt</td>\n",
       "      <td>Gift Receipt</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>https://www.netflix.com/watch/80986856?t=563</td>\n",
       "      <td>Maybe I'll go for this. That could be a good o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>house-party</td>\n",
       "      <td>House Party</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>82</td>\n",
       "      <td>https://www.netflix.com/watch/81643783?t=413</td>\n",
       "      <td>Right? It's so nice you live this close. Yeah....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>banana-breath</td>\n",
       "      <td>Banana Breath</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>83</td>\n",
       "      <td>https://www.netflix.com/watch/81643784?t=7</td>\n",
       "      <td>I'm gonna show a quick scenario that has right...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>photo-wall-of-metal-metal-motto-search</td>\n",
       "      <td>Photo Wall of Metal: Metal Motto Search</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>84</td>\n",
       "      <td>https://www.netflix.com/watch/81643784?t=206</td>\n",
       "      <td>Welcome to Photo Wall of Metal, the Metal Mott...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>don-bondarley-king-of-the-dirty-songs</td>\n",
       "      <td>Don Bondarley, King of the Dirty Songs</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>85</td>\n",
       "      <td>https://www.netflix.com/watch/81643784?t=404</td>\n",
       "      <td>Seriously, this has been a perfect weekend so ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>tasty-time-vids</td>\n",
       "      <td>Tasty Time Vids</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>86</td>\n",
       "      <td>https://www.netflix.com/watch/81643784?t=596</td>\n",
       "      <td>All right, everybody, let's get those lunch or...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      slug  \\\n",
       "0                                both-ways   \n",
       "1            has-this-ever-happened-to-you   \n",
       "2                         baby-of-the-year   \n",
       "3                                instagram   \n",
       "4                             gift-receipt   \n",
       "..                                     ...   \n",
       "81                             house-party   \n",
       "82                           banana-breath   \n",
       "83  photo-wall-of-metal-metal-motto-search   \n",
       "84   don-bondarley-king-of-the-dirty-songs   \n",
       "85                         tasty-time-vids   \n",
       "\n",
       "                                       name  season  episode  id  \\\n",
       "0                                 Both Ways       1        1   1   \n",
       "1             Has This Ever Happened To You       1        1   2   \n",
       "2                          Baby of the Year       1        1   3   \n",
       "3                                 Instagram       1        1   4   \n",
       "4                              Gift Receipt       1        1   5   \n",
       "..                                      ...     ...      ...  ..   \n",
       "81                              House Party       3        5  82   \n",
       "82                            Banana Breath       3        6  83   \n",
       "83  Photo Wall of Metal: Metal Motto Search       3        6  84   \n",
       "84   Don Bondarley, King of the Dirty Songs       3        6  85   \n",
       "85                          Tasty Time Vids       3        6  86   \n",
       "\n",
       "                                     netflixLink  \\\n",
       "0     https://www.netflix.com/watch/80986856?t=7   \n",
       "1   https://www.netflix.com/watch/80986856?t=101   \n",
       "2   https://www.netflix.com/watch/80986856?t=208   \n",
       "3   https://www.netflix.com/watch/80986856?t=444   \n",
       "4   https://www.netflix.com/watch/80986856?t=563   \n",
       "..                                           ...   \n",
       "81  https://www.netflix.com/watch/81643783?t=413   \n",
       "82    https://www.netflix.com/watch/81643784?t=7   \n",
       "83  https://www.netflix.com/watch/81643784?t=206   \n",
       "84  https://www.netflix.com/watch/81643784?t=404   \n",
       "85  https://www.netflix.com/watch/81643784?t=596   \n",
       "\n",
       "                                           transcript  \n",
       "0   Obviously, I'd love to work for you, and I app...  \n",
       "1   Have you been the victim of unfair treatment b...  \n",
       "2   Look at their rolls. Look at their folds. Look...  \n",
       "3   Let me see it. Oh yeah that's good. That's gre...  \n",
       "4   Maybe I'll go for this. That could be a good o...  \n",
       "..                                                ...  \n",
       "81  Right? It's so nice you live this close. Yeah....  \n",
       "82  I'm gonna show a quick scenario that has right...  \n",
       "83  Welcome to Photo Wall of Metal, the Metal Mott...  \n",
       "84  Seriously, this has been a perfect weekend so ...  \n",
       "85  All right, everybody, let's get those lunch or...  \n",
       "\n",
       "[86 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bdb4185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 86 entries, 0 to 85\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   slug         86 non-null     object\n",
      " 1   name         86 non-null     object\n",
      " 2   season       86 non-null     int64 \n",
      " 3   episode      86 non-null     int64 \n",
      " 4   id           86 non-null     int64 \n",
      " 5   netflixLink  86 non-null     object\n",
      " 6   transcript   86 non-null     object\n",
      "dtypes: int64(3), object(4)\n",
      "memory usage: 4.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f236952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"All right, everybody, let's get those lunch orders in. Put your order in, right into the app. Ooh, Trebinetti's. David, can I talk to you? Of course. I love their salads. Draven. Don't know if we're gonna have enough GOTV buses for this weekend without Mike Flaherty. Okay. This isn't the first time Mike flaked. Concerns me come primary day. I don't know what other options we have. I asked Lynn to quietly check with George Faust if he's willing to help. I'd love not to go down that road. You could talk to him, but I know him more than anyone so I don't know what'll help. Let me think. Thank you for bringing it to my attention. Oh, thank you. All right. Everybody all in? Everybody good? Let's go. Get motivated. Fifteen days. Fifteen days. All right! I'm mad at you. What? I'm mad at you! You're not following me on Instagram. Oh. Didn't know you were on there. I'm on there. I'll look. I'll find you. It's okay. I followed myself from your phone. You followed yourself from my phone? What the hell is this? Tasty Time Vids. Me. Check it out. I post funny stuff. New videos starting today. Every Friday. Every Friday! Rain or shine, a new funny video. Don't worry. Cool. Yeah, I'll check it out, Draven. Yeah, you will 'cause you follow me. Thanks for the follow, fan. All right, cool. Yeah. Gonna move boxes, but first a word with you. The hell you doing, you little asshat? You little stupid fucking piece of shit. Shut up. Okay. All right. Gonna be looking for you on the computer. New vid dropped. Watch it right now. In the morning. Watch! Wow. That was really amazing. Glad I met you at the bar. What the fuck is this? You should go. I think I just slept with Frankenstein's chick! Oh no! Tasty Time Videos every Friday. It's great. Thank you for encouraging me. Thank you for believing in me, David. New video next Friday! fuck! Hey, Draven, Draven, Draven! What is going on? I can't fucking think of anything! Anything for what? For this video! I can't think of anything funny. Don't know what I'm gonna do. Probably be okay. They're coming after me in the comments! The woman that played Frankenstein's chick is saying I... paid her in fast food. Saying I paid her in a Santa Fe chicken sandwich. Why are they saying you paid in fast food? Why would they say that? 'Cause I did! I don't know how to do this stuff. I'm... I'm so dead. I don't know what to do, man. You're responsible for me on some level. You encouraged me. I don't know how to help. fuck! Draven! Draven! Draven! fucking shit! David. I am so worried about this video. Just made it! Phew! I slept with Frankenstein's chick! Oh no! Frankenstein's Chick Sped Up. Pays in Santa Fe sandwich. Pays in fast food. Gonna kill this guy's parents. Gonna murder his dad. Paid her in pencil fries. I wanna kill his mom. Oh my God. See the vid? Did you see it? Yeah. Yeah! Frankenstein's Chick, sped up twice as fast. It worked! Yes. See they wanna kill my parents? Yeah, I saw that. I saw that. Saying they're gonna cut my dad's head off. Jesus. Frankenstein's chick and her manager are coming after me. They want to take my account away. Telling everybody I paid her in Arby's. You did. Goddammit! This is your fault. How? When you gave me your phone. Shouldn't give your phone to people you don't really know. Plus I'm frozen. Zero ideas. I can't think of what I'm gonna do next. And I can't think of any ideas! Oh my God! This is your fault. You encouraged me. You're responsible for me. Cut my dad's head off. I'm fucking dead. It's all over, David. Don't be scared. Don't be sad. Watch this. You're being crazy, Frankenstein. I didn't cheat! What's this then? Uh-oh. Hey, everyone. I'm the new owner of Tasty Time Vids. She's Frankenstein's chick and I'm her manager. Jesus Christ. The hell is this? I gave away Tasty Time Vids. Did it for my dad. No one's ever getting this head. No one's ever cutting off my daddy's head. I love my daddy. Me and papa. Does your dad smoke? We should hang out.\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcripts = df['transcript'].to_list()\n",
    "transcripts[-1] # peek at last item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afc6f2e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Obviously, I'd love to work for you, and I appreciate you taking the time to meet with me. I... I feel good about it. I hope I didn't do too much talking.\\nNo, you were great. You were great.\\nI hope to hear from you soon. We'll be in touch.\\nReally nice meeting you. Nice to meet you as well. Okay. Oh!\\nLooks like you push.\\nOh, it does both.\\nWhat?\\nIt does both. I was here yesterday, and it actually goes both ways.\\nOh, okay. Okay, see you. See? Hope to hear from you soon.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcripts[0] # peek at first item"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f056d6",
   "metadata": {},
   "source": [
    "The first sketch seems to be the only one with \\n line breaks so I'll remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c4f6c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace \\n with a space\n",
    "transcripts[0] = transcripts[0].replace('\\n', ' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b304a64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Obviously, I'd love to work for you, and I appreciate you taking the time to meet with me. I... I feel good about it. I hope I didn't do too much talking. No, you were great. You were great. I hope to hear from you soon. We'll be in touch. Really nice meeting you. Nice to meet you as well. Okay. Oh! Looks like you push. Oh, it does both. What? It does both. I was here yesterday, and it actually goes both ways. Oh, okay. Okay, see you. See? Hope to hear from you soon.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify that it was replaced\n",
    "transcripts[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01d0f02",
   "metadata": {},
   "source": [
    "note to self: remember to download model first\n",
    "\n",
    "`% python -m spacy download en_core_web_sm`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d2b5ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load language model (en_core_web_sm) to process transcripts\n",
    "# process an index number with nlp()\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "docs = nlp(transcripts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f7dcf35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obviously, I'd love to work for you, and I appreciate you taking the time to meet with me.\n",
      "I...\n",
      "I feel good about it.\n",
      "I hope I didn't do too much talking.\n",
      "No, you were great.\n",
      "You were great.\n",
      "I hope to hear from you soon.\n",
      "We'll be in touch.\n",
      "Really nice meeting you.\n",
      "Nice to meet you as well.\n",
      "Okay.\n",
      "Oh!\n",
      "Looks like you push.\n",
      "Oh, it does both.\n",
      "What?\n",
      "It does both.\n",
      "I was here yesterday, and it actually goes both ways.\n",
      "Oh, okay.\n",
      "Okay, see you.\n",
      "See?\n",
      "Hope to hear from you soon.\n"
     ]
    }
   ],
   "source": [
    "# get sentences (sent) from one sketch transcript\n",
    "for i in docs.sents:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6df773bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 86 sketches...\n",
      "Processed 10/86 sketches...\n",
      "Processed 20/86 sketches...\n",
      "Processed 30/86 sketches...\n",
      "Processed 40/86 sketches...\n",
      "Processed 50/86 sketches...\n",
      "Processed 60/86 sketches...\n",
      "Processed 70/86 sketches...\n",
      "Processed 80/86 sketches...\n",
      "Done! Extracted 6509 sentences from 86 sketches.\n"
     ]
    }
   ],
   "source": [
    "# Extract sentences from all sketches using spaCy\n",
    "sentences_data = []\n",
    "\n",
    "print(f\"Processing {len(df)} sketches...\")\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    sketch_id = row['id']\n",
    "    sketch_name = row['name']\n",
    "    slug = row['slug']\n",
    "    season = row['season']\n",
    "    episode = row['episode']\n",
    "    transcript = row['transcript']\n",
    "    \n",
    "    # Process transcript with spaCy\n",
    "    doc = nlp(transcript)\n",
    "    \n",
    "    # Extract sentences\n",
    "    # Note: 'sent' is a Span object (a slice/view of the Doc)\n",
    "    # Span objects have a .text attribute that gives you the sentence as a string\n",
    "    for sent_idx, sent in enumerate(doc.sents, start=1):\n",
    "        sentence_text = sent.text.strip()  # sent.text extracts the string from the Span\n",
    "        \n",
    "        # Skip empty sentences\n",
    "        if not sentence_text:\n",
    "            continue\n",
    "            \n",
    "        sentences_data.append({\n",
    "            'sketch_id': sketch_id,\n",
    "            'sketch_name': sketch_name,\n",
    "            'slug': slug,\n",
    "            'season': season,\n",
    "            'episode': episode,\n",
    "            'sentence_index': sent_idx,\n",
    "            'sentence_text': sentence_text\n",
    "        })\n",
    "    \n",
    "    if (idx + 1) % 10 == 0:\n",
    "        print(f\"Processed {idx + 1}/{len(df)} sketches...\")\n",
    "\n",
    "print(f\"Done! Extracted {len(sentences_data)} sentences from {len(df)} sketches.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b5abf435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total sentences extracted: 6509\n",
      "\n",
      "Sentences per sketch statistics:\n",
      "count     86.000000\n",
      "mean      75.686047\n",
      "std       38.871209\n",
      "min        4.000000\n",
      "25%       51.250000\n",
      "50%       75.000000\n",
      "75%       95.000000\n",
      "max      199.000000\n",
      "dtype: float64\n",
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sketch_id</th>\n",
       "      <th>sketch_name</th>\n",
       "      <th>slug</th>\n",
       "      <th>season</th>\n",
       "      <th>episode</th>\n",
       "      <th>sentence_index</th>\n",
       "      <th>sentence_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Both Ways</td>\n",
       "      <td>both-ways</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Obviously, I'd love to work for you, and I app...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Both Ways</td>\n",
       "      <td>both-ways</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Both Ways</td>\n",
       "      <td>both-ways</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>I feel good about it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Both Ways</td>\n",
       "      <td>both-ways</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>I hope I didn't do too much talking.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Both Ways</td>\n",
       "      <td>both-ways</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>No, you were great.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>Both Ways</td>\n",
       "      <td>both-ways</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>You were great.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>Both Ways</td>\n",
       "      <td>both-ways</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>I hope to hear from you soon.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>Both Ways</td>\n",
       "      <td>both-ways</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>We'll be in touch.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>Both Ways</td>\n",
       "      <td>both-ways</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>Really nice meeting you.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>Both Ways</td>\n",
       "      <td>both-ways</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>Nice to meet you as well.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sketch_id sketch_name       slug  season  episode  sentence_index  \\\n",
       "0          1   Both Ways  both-ways       1        1               1   \n",
       "1          1   Both Ways  both-ways       1        1               2   \n",
       "2          1   Both Ways  both-ways       1        1               3   \n",
       "3          1   Both Ways  both-ways       1        1               4   \n",
       "4          1   Both Ways  both-ways       1        1               5   \n",
       "5          1   Both Ways  both-ways       1        1               6   \n",
       "6          1   Both Ways  both-ways       1        1               7   \n",
       "7          1   Both Ways  both-ways       1        1               8   \n",
       "8          1   Both Ways  both-ways       1        1               9   \n",
       "9          1   Both Ways  both-ways       1        1              10   \n",
       "\n",
       "                                       sentence_text  \n",
       "0  Obviously, I'd love to work for you, and I app...  \n",
       "1                                               I...  \n",
       "2                              I feel good about it.  \n",
       "3               I hope I didn't do too much talking.  \n",
       "4                                No, you were great.  \n",
       "5                                    You were great.  \n",
       "6                      I hope to hear from you soon.  \n",
       "7                                 We'll be in touch.  \n",
       "8                           Really nice meeting you.  \n",
       "9                          Nice to meet you as well.  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame from the extracted sentences\n",
    "sentences_df = pd.DataFrame(sentences_data)\n",
    "\n",
    "# Display summary information\n",
    "print(f\"\\nTotal sentences extracted: {len(sentences_df)}\")\n",
    "print(f\"\\nSentences per sketch statistics:\")\n",
    "print(sentences_df.groupby('sketch_id').size().describe())\n",
    "print(f\"\\nFirst few rows:\")\n",
    "sentences_df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "77935cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to 'sentences_extracted.csv'\n",
      "Saved to 'sentences_extracted.json'\n"
     ]
    }
   ],
   "source": [
    "# Save to CSV format (useful for pandas/huggingface datasets)\n",
    "sentences_df.to_csv('sentences_extracted.csv', index=False)\n",
    "print(\"Saved to 'sentences_extracted.csv'\")\n",
    "\n",
    "# Save to JSON format (useful for huggingface transformers)\n",
    "sentences_df.to_json('sentences_extracted.json', orient='records', indent=2)\n",
    "print(\"Saved to 'sentences_extracted.json'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
